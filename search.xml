<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mybatis技术内幕]]></title>
    <url>%2F2019%2F03%2F29%2FMybatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Redis实战]]></title>
    <url>%2F2019%2F02%2F27%2FRedis%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[一些基础知识点 Redis五种基本数据类型： String: Redis的字符串由多个字节组成，是动态字符串，是可以修改的字符串，内部实现类似于Java的ArrayList,字符串最大长度为512M。 List： Redis的列表相当于Java的LinkedList,底层实现是quicklist（[prev+ziplist+next]…..[…]…）这种数据结构，可以实现队列和栈这种数据结构，lindex 相当于Java中的getIndex(x)函数，ltrim 用于实现定长的链表。 Hash: Redis的字典相当于Java语言里面的HashMap（数组+链表） Set: Redis的集合相当于Java中的HashSet.(无序且唯一) ZSet: Redis的有序集合相当于Java中的SortedSet和HashMap的合体，ZSet内部的排序功能是通过跳跃列表这种数据结构来实现的， ZSet,Set,Hash,List都是容器型数据结构，其通用规则是： create if not exists(对容器的操作，若容器不存在，先创建容器，在进行容器中元素操作)。drop if no elements（若容器中没有元素，删除该容器）。 Redis的五种基本数据类型都能设置过期时间，该过期时间针对key,(Tips:针对String类型的设置过期时间会在执行set key 命令后使过期时间失效)。 Redis的持久化策略：RDB:在指定的时间内将snapshot快照写入磁盘，恢复时将文件直接读入内存，场景分析：大规模数据的恢复，且对数据恢复的完整性 不敏感。最后一次持久化后的数据可能丢失。 AOF:以日志的形式来记录每个写操作.使用场景：备份机制更稳健，丢失数据概率更低，日志文本可读。 Redis的消息订阅和发布：按照频道订阅，可以一次订阅多个，发布者发布后，收到消息。可以按照规则订阅，订阅多个，使用通配符* Redis的使用场景： 高速数据缓存服务， 分布式session共享：使用redis集群做session共享服务器， 分布式锁：最简单的方式在实例里创建一个键值，使用Jedis set（key,requestId,NX,EX,30000）;使用唯一key作为锁，相应的value作为对应的请求的Id,可避免加锁和解锁不是同一个人这种情况，使用过期时间可保证客户端宕机不会发生死锁的情况，锁到时间会自动删除，且必须保证任意时刻，只有一个客户端持有锁。 Redis集群采用一主多仆方式，或多主多仆方式，主（写）从（读）之间通过同步命令不断复制数据，仆服务器读取主的RDB文件。当主机挂掉，需要手动让仆成为主机，如果通过哨兵模式，仆服务器可自动成为主服务器 哨兵服务器:负责服务器的投票抉择问题，根据从服务器的优先级决定谁成为主服务器。 缓存问题： 缓存并发:缓存过期或者在更新，且同时存在大量并发请求该key，导致的缓存失效，请求直接到达数据库层会导致数据一致性问题，或者服务“雪崩”。解决方法是对更新缓存时的缓存查询操作加锁，阻塞直至成功重建缓存。 缓存雪崩：当缓存失效时间相同时，可能导致同时大量缓存同时失效，导致数据库查询压力骤增，引发雪崩，可将缓存失效时间均匀平摊在时间轴上。 缓存击穿：某个key对应的数据为空，缓存没有命中，导致不必要的数据库查询操作，通过设置布隆过滤器，将有可能存在的数据hash到一个足够大的bitmap中。一个一定不存在的数据一定会被过滤掉，一个可能存在过的数据也可能被过滤掉，这是布隆过滤器的误判率，但是不妨碍缓存的性能。从而避免了请求直达数据库。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试知识点整理-3]]></title>
    <url>%2F2019%2F02%2F19%2F%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86-3%2F</url>
    <content type="text"><![CDATA[RocketMQ相关 为什么使用消息中间件： 无消息中间件的分布式系统存在性能瓶颈，多个事务请求无论采用串行方式处理，还是并行方式处理，在硬件（Cpu） 固定下，系统的吞吐量(QPS或者TPS)无法达到要求，主要是响应时间过长，因此，利用消息中间件我们可以减少响应时间（异步返回处理结果）。提高QPS. 多个相关连的系统之间的耦合性问题，若A系统强依赖B系统，一旦B系统出现问题，将导致整个业务链路的失败，加入了消息队列后，A系统将相关的消息直接写入消息队列，然后给客户端调用成功，此时B系统若订阅了A系统的消息，然后采用push 或者pull 的方式，获取A系统的相关消息，再进行业务操作。实现了系统之间的解耦操作。 高QPS导致的问题，在一些大流量的场景下，应用无法承受如此高的负载，导致应用挂掉，此时在应用的前端加入消息中间件系统就能有效的起到削峰限流的作用，主要体现在可以控制应用系统访问的人数，限制短时间内的大规模访问。当用户请求量到达一定的阈值，进行请求丢弃或者延时请求操作。 日志处理 ，通过日志采集客户端的定时采集发送到kafka 消息队列，消息队列进行大规模日志数据消息的接受，存储和转发，然后日志处理端获取到转发的日志消息进行处理。 mq异步解耦指的是：挡住前端请求数据的洪峰，保证后端系统的稳定性。异步要求服务端对数据的实时性要求不高，对数据的可靠性要求高。 使用场景：（1）发布订阅模式，（2）消息优先级有要求（3）消息有序性要求，如购物行为。（4）消息过滤，无用消息的处理（5）消息的持久化（数库库或者KV存储系统或者文件等））（5）回溯消费，消息重试，定时消息，分布式事务等等。]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试知识点整理-2]]></title>
    <url>%2F2018%2F11%2F02%2F%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86-2%2F</url>
    <content type="text"><![CDATA[学习笔记工厂方法模式中有一个问题，添加一个新的产品时，可以在客户端代码中直接通过xml+反射机制来生成产品对象，在定义产品对象时使用抽象类型，同样可以确保系统的灵活性和可扩展性，增加新的具体产品类无须修改源代码，只需要将其作为抽象产品类的子类再修改配置文件即可，根本不需要抽象工厂类和具体工厂类，这个答案应该是：创建对象与使用对象-工厂的作用-https://blog.csdn.net/will130/article/details/50446287 面试相关 Restful: Rest是一种设计原则，分为几个方面。(1),网络上的所有事物都被抽象为资源，每个资源都有唯一的一个资源标识符，同一个资源具有多重表现形式，所有的操作都是无状态的，符合Rest原则架构方式即可成称为Restful. 幂等性：对同一Rest接口的多次访问，得到的资源状态是相同的 spring的IOC和DI: https://blog.csdn.net/luoyepiaoxue2014/article/details/72426666 注解@Autowired,@Inject,@Resource @Autowired是spring自带的，@Inject是JSR330规范实现的，@Resource是JSR250规范实现的，需要导入不同的包 @Autowired、@Inject用法基本一样，不同的是@Autowired有一个request属性 @Autowired、@Inject是默认按照类型匹配的，@Resource是按照名称匹配的 @Autowired如果需要按照名称匹配需要和@Qualifier一起使用，@Inject和@Name一起使用 在ajax post 请求中，请求体数据可以是两种类型，既content-type:application/x-www-form-urlencoded或者是application/json, application/xml这种，前者常用来发送简单的请求体数据，如{“a”:”b”,”c”:1}，在SpringMVC的处理也比较简单，传入几个参数，控制器方法几个参数即可，默认这种简单数据类型转换是由ConversionService配置的转换器完成，同样，也可在方法的参数上注入@RequestParam 注解，效果相同，（此注解只针对String,int等基本数据类型的转换)。 另外，针对对象类型既model类的请求体，通常采用@ResponseBody 注解在相应的方法参数上，作为ajax 请求体数据的映射，@ResponseBody 也可以省略，@ResponseBody通常和ContentType:application/json, ContentType:application/xml,搭配使用。 最后，针对既有对象类型，又有普通数据类型的请求体数据，可在前端将请求体转化为Json字符串，在拼接成一个基本数据类型的请求体,如{“key”:”JSon字符串”}，后端MVC只通过简单的@RequestParam注解即可获取相应的值，然后进行JSON字符串的解析即可拿到相应的里面的对象和其他基本数据类型。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>Java Web - 面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nettyt通信框架实战]]></title>
    <url>%2F2018%2F09%2F17%2FNettty%E9%80%9A%E4%BF%A1%E6%A1%86%E6%9E%B6%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Netty_Server启动流程 Netty中的Reactor线程模型的主体类关系图 AbstractServerBootStrap分析 服务启动的方法入口是sbs.bind(port),需要验证sbs(ServerBootStrap)对象绑定的Group和channel和InetSocketDresss是否为空,不为空继续下一步，接下来就是初始化并且注册到Selector上去，绑定到本地端口。 initAndRegister() 123456789101112131415161718192021222324252627final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); init(channel); &#125; catch (Throwable t)&#123;&#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; &#125; &#125;``` channelFactory.newChannel()方法，其中channelFactory在AbstractBootStarp类中被赋值的地方可以发现: &gt; channel() ```Javapublic B channel(Class&lt;? extends C\&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException("channelClass"); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass)); &#125; 其实他是一个ReflectiveChannelFactory实例，进入此实例中发现其工厂类真正实现方法主体如下: newChannel() 12345try &#123; return clazz.newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException("Unable to create Channel from class " \+ clazz, t); &#125; channelClass其实就是我们在Server启动类中调用的serverBootStrap.group.channel(NioServerSocketChannel.class),由此可见，这里真正的Channel实例就是NioServerSocketChannel，在NioServerSocketChannel类的初始化过程中，初始化了一系列的netty核心组件，如Channel ,ChannelConfig,ChannelId,Unsafe,ChannelPipline,ChannelHandler等。 然后我们进入init方法，实现是在其子类ServerBootStrap中,此方法的前戏是对一些我们在启动类中的属性和选项的设置，略过，真正主体是如下方法代码, init() 12345678910111213141516171819202122232425//...channel.config().setOptions(options);//...channel.attr(key).set(e.getValue());//...ChannelPipeline p = channel.pipeline();//新连接 channel 的 ChildOptions 和 ChildAttr 设置...//新连接 channel 加入处理p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); init方法也并没有将此channel 注册到某个事件循环器上只是初始化了该serverChannel的一些属性，还有当有新的连接channel进来时的一些属性设置,并且将这些新的连接的属性封装成一个接入器对象里面，将这个接入器对象放入到该serverChannel的管道对象中，这些新的连接的处理都在Reactor事件循环器中被异步处理，继续进行下一个方法分析，ChannelFuture regFuture = config().group().register(channel);，通过ChannelConfig拿到EventLoopGroup对象，再进入到EventLoopGroup的实现MultithreadEventLoopGoup的register(channel)方法中。 MultithreadEventLoopGroup： 1234@Override public ChannelFuture register(Channel channel) &#123; return next().register(channel); &#125; next()方法是EventExecutorChooser定义的方法，EventExecutorChooser.next()方法的默认实现是DefaultEventChooserFactory,查看此工厂类可知时间执行选择器的实现有两种（根据EvenetExecutor数组的长度是否是2的整数次幂决定选用那种Chooser），每种chooser获取eventExecutor的方式不同，一种是idx和数组长度做与运算，一种是idx模除数组长度，取绝对值拿到数组下标，取得对应的EventExecutor对象。获取到对象的EventExecutor对象后，强转为EventLoop接口对象，跳转到SingleThreadEventLoop类的register方法中，如下所示： SingleThreadEventLoop 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Override public ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this)); &#125; @Override public ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.*checkNotNull*(promise, "promise"); promise.channel().unsafe().register(this, promise); return promise; &#125;``` 拿到前期已经初始化的*AbstractUnsafe*对象进行注册操作，进入register方法中,判断事件循环执行器是否已经绑定到该ServerChannel上,判断该事件循环执行器是否属于NioEventLoop，既是否兼容，然后将该事件循环器绑定到该serverChannel上 =&gt; *AbstractChannel.this.eventLoop = eventLoop* ,然后判断当前线程是不是事件循环执行器线程，如果是，执行register0()方法. &gt; AbstractChannel.AbstactUnsafe implements Unsafe```Java@Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; throw new NullPointerException("eventLoop"); &#125; if (isRegistered()) &#123; promise.setFailure(new IllegalStateException("registered to an event loop already")); return; &#125; if (!isCompatible(eventLoop)) &#123; promise.setFailure( new IllegalStateException("incompatible event loop type: " + eventLoop.getClass().getName())); return; &#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; logger.warn( "Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; &#125; register0方法中，先进行doRegister方法的调用，然后调用管道的invokeHandlerAddedIfNeeder(),方法，此时，handler才是被正式加入到pipline管道中。然后出发channel注册事件，该handler和pipeline管道正式进行绑定成功，在进行isActive()方法判断的时候，返回值为false,管道的fireChannelActive()方法未被执行. 1234567891011121314151617181920212223242526272829private void register0(ChannelPromise promise) &#123; try &#123; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; 至此，register方法执行完毕，initAndRegister方法也执行完了，返回一个ChannelFuture对象到doBind()方法中：最后在此方法中进行一系列的判断，到达doBind0()方法： AbstarctBootStrap 1234567891011121314private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;); &#125; doBind0中的bind操作被加入到reactor线程组中异步执行绑定操作，我们定位到bind方法中，首先进入到AbstractChannel中的bind方法，接着进入到DefaultChannelPipline中的bind方法。 AbstractChannel 1234@Overridepublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return pipeline.bind(localAddress, promise);&#125; DefaultChannelPipline 1234@Overridepublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return tail.bind(localAddress, promise);&#125; tail 对象在创建默认管道对象的时候被创建，现在不用理会，继续往下跟进，进入到 AbstractChannel.AbstractUnsafe-&gt;NioMessageUnsafe 12345678910111213141516171819202122@Override public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; assertEventLoop(); //... boolean wasActive = isActive(); try &#123; doBind(localAddress); &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); closeIfClosed(); return; &#125; if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise); &#125; 此方法的wasActive 是false,进入到dobind(localAddress)方法中： NioServerSocketChannel 12345678@Override protected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.*javaVersion*() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125; &#125; 这里面的代码是调用JDK的Socket端口绑定方法进行绑定。绑定后 isActive()方法就是返回true了（已经被绑定成功），就会进入上个方法if判断条件中，进入下一步的pipline.fireChannelActive()方法。 DefaultChannelPipline 12345@Overridepublic final ChannelPipeline fireChannelActive() &#123; AbstractChannelHandlerContext.invokeChannelActive(head); return this;&#125; AbstractChannelHandlerContext 12345678910111213141516171819202122232425static void invokeChannelActive(final AbstractChannelHandlerContext next) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelActive(); &#125; else &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; next.invokeChannelActive(); &#125; &#125;); &#125;&#125;private void invokeChannelActive() &#123; if (invokeHandler()) &#123; try &#123; ((ChannelInboundHandler) handler()).channelActive(this); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125; &#125; else &#123; fireChannelActive(); &#125;&#125; 拿到ServerChannel的事件循环执行器，next对象即是abstractChannelHandlerContext对象。继续进入((ChannelInboundHandler) handler().channelActive(this)方法。此方法第一次调用时会进入如下； DefaultChannelPipline.HeadContext 12345@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive(); readIfIsAutoRead();&#125; 继续向下执行回调到AbstactChannelHandlerContext类中的方法,又会执行到((ChannelInboundHandler) handler().channelActive(this)方法，这里的handler()方法每次返回的对象都不一样，导致这个方法会重复调用三次，第二次调用channelActive(this)方法会进入到ChannelInboundHandlerAdapter中， ChannelInboundHandlerAdapter 1234@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive();&#125; 方法执行回到AbstractChannelHandlerContext中，会第三次调用ChannelActive(this)方法， AbstractChannelHandlerContext 12345@Override public ChannelHandlerContext fireChannelActive() &#123; final AbstractChannelHandlerContext next = findContextInbound(); *invokeChannelActive*(next); return this;&#125; 第三次调用channelActive(this)方法会跳转到，DefaultChannelPipline.TailContext的方法中： DefaultChannelPipline.TailContext 12@Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; &#125; 自此，执行完毕。]]></content>
      <tags>
        <tag>Netty</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eureka_源码解析]]></title>
    <url>%2F2018%2F08%2F27%2Feureka-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[微服务应用使用eureka作为注册中心的核心注解@EnableDiscoveryClient12345678@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;EnableDiscoveryClientImportSelector.class&#125;)public @interface EnableDiscoveryClient &#123; boolean autoRegister() default true;&#125; 主要类关系图 DiscoveryClient(com.netflix包下的Eureka client相关)此类是真正实现服务获取，服务注册，续约，的相关类，在此类的构造函数中1234567@Inject DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider&lt;BackupRegistry&gt; backupRegistryProvider) &#123; this.RECONCILE_HASH_CODES_MISMATCH = Monitors.newCounter("DiscoveryClient_ReconcileHashCodeMismatch"); this.FETCH_REGISTRY_TIMER = Monitors.newTimer("DiscoveryClient_FetchRegistry"); // ..... this.initScheduledTasks(); // ..... 有一个初始化定时任务函数，这个函数内部就是和服务注册相关的，进入此函数12345678910111213141516171819202122232425262728293031323334353637383940private void initScheduledTasks() &#123; int renewalIntervalInSecs; int expBackOffBound; if (this.clientConfig.shouldFetchRegistry()) &#123; renewalIntervalInSecs = this.clientConfig.getRegistryFetchIntervalSeconds(); expBackOffBound = this.clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); this.scheduler.schedule(new TimedSupervisorTask("cacheRefresh", this.scheduler, this.cacheRefreshExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.CacheRefreshThread()), (long)renewalIntervalInSecs, TimeUnit.SECONDS); &#125; if (this.clientConfig.shouldRegisterWithEureka()) &#123; renewalIntervalInSecs = this.instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); expBackOffBound = this.clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: renew interval is: " + renewalIntervalInSecs); this.scheduler.schedule(new TimedSupervisorTask("heartbeat", this.scheduler, this.heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.HeartbeatThread(null)), (long)renewalIntervalInSecs, TimeUnit.SECONDS); this.instanceInfoReplicator = new InstanceInfoReplicator(this, this.instanceInfo, this.clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); this.statusChangeListener = new StatusChangeListener() &#123; public String getId() &#123; return "statusChangeListener"; &#125; public void notify(StatusChangeEvent statusChangeEvent) &#123; if (InstanceStatus.DOWN != statusChangeEvent.getStatus() &amp;&amp; InstanceStatus.DOWN != statusChangeEvent.getPreviousStatus()) &#123; DiscoveryClient.logger.info("Saw local status change event &#123;&#125;", statusChangeEvent); &#125; else &#123; DiscoveryClient.logger.warn("Saw local status change event &#123;&#125;", statusChangeEvent); &#125; DiscoveryClient.this.instanceInfoReplicator.onDemandUpdate(); &#125; &#125;; if (this.clientConfig.shouldOnDemandUpdateStatusChange()) &#123; this.applicationInfoManager.registerStatusChangeListener(this.statusChangeListener); &#125; this.instanceInfoReplicator.start(this.clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); &#125; else &#123; logger.info("Not registering with Eureka server per configuration"); &#125; &#125; 在 if (this.clientConfig.shouldRegisterWithEureka()) 分支内实现了服务续约和服务注册的功能，服务注册和服务续约是两个共生功能，服务续约使用心跳的方式去续约。具体实现注册则是在 this.instancewInfoReplicator.start(…)方法中，这个线程的run()方法如下 1234567891011121314151617181920212223242526272829303132333435public void run() &#123; boolean var6 = false; ScheduledFuture next; label53: &#123; try &#123; var6 = true; this.discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = this.instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) &#123; this.discoveryClient.register(); this.instanceInfo.unsetIsDirty(dirtyTimestamp); var6 = false; &#125; else &#123; var6 = false; &#125; break label53; &#125; catch (Throwable var7) &#123; logger.warn("There was a problem with the instance info replicator", var7); var6 = false; &#125; finally &#123; if (var6) &#123; ScheduledFuture next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); &#125; &#125; next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); return; &#125; next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); &#125; 不难看出，this.discoveryClient.register()是真正的注册方法，进入此方法1234567891011121314151617boolean register() throws Throwable &#123; logger.info("DiscoveryClient_" + this.appPathIdentifier + ": registering service..."); EurekaHttpResponse httpResponse; try &#123; httpResponse = this.eurekaTransport.registrationClient.register(this.instanceInfo); &#125; catch (Exception var3) &#123; logger.warn("&#123;&#125; - registration failed &#123;&#125;", new Object[]&#123;"DiscoveryClient_" + this.appPathIdentifier, var3.getMessage(), var3&#125;); throw var3; &#125; if (logger.isInfoEnabled()) &#123; logger.info("&#123;&#125; - registration status: &#123;&#125;", "DiscoveryClient_" + this.appPathIdentifier, httpResponse.getStatusCode()); &#125; return httpResponse.getStatusCode() == 204; &#125; 此方法中的this.eurekaTransport 内部类是DiscoveryClient实现的一个HTTP请求包装类，利用其中的一些属性进行Restful风格的请求注册，具体实现类应为RestTemplateEurekaHttpClient，此实现类实现了EurekaHttpClient,并将注册请求发送给服务端，客户端拿到响应进行响应的处理返回。说完服务注册，服务续约相关的主要是两个变量,如下两个变量主要控制服务续约相关，renewIntervalInsecs是调整服务续约任务的调用间隔时间，expBackOffBound是定义服务时效时间。对应配置文件的两个设置项。 12renewalIntervalInSecs = this.instanceInfo.getLeaseInfo().getRenewalIntervalInSecs();expBackOffBound = this.clientConfig.getHeartbeatExecutorExponentialBackOffBound(); 服务获取对应的逻辑判断条件是if (this.clientConfig.shouldFetchRegistry()) 这个属性对应的也是配置文件中的一个属性 eureka.client.fetch-registry=true 默认为true.为了定期更新客户端的服务清单，需要一个定时任务去从服务端获取服务清单，这个定时任务的频率可以设置，具体配置属性就是eureka.client.registry-fetch-interval-seconds= xxx 。服务获取的内部具体实现分为第一次获取和刷新缓存服务清单（非第一次获取）new DiscoveryClient.CacheRefreshThread()方法。对于服务续约，具体的实现函数为new DiscoveryClient.HeartbeatThread(null)，都是发送的Rest请求进行。 Eureka Server(服务端)Eureka Server 对于Rest请求的处理都在com.netflix.eureka.resources包下。在ApplicationResource类中， 12345678@POST@Consumes(&#123;"application/json", "application/xml"&#125;)public Response addInstance(InstanceInfo info, @HeaderParam("x-netflix-discovery-replication") String isReplication) &#123; logger.debug("Registering instance &#123;&#125; (replication=&#123;&#125;)", info.getId(), isReplication); // ....对传来的实例的元数据信息进行校验 registry.register(info ,"true".equals(isReplication)); return Response.status(204).build();//204 转发 &#125; register中的注册的具体实现为InstanceRegistry类的register重写方法，如下1234public void register(InstanceInfo info, boolean isReplication) &#123; this.handleRegistration(info, this.resolveInstanceLeaseDuration(info), isReplication); super.register(info, isReplication);&#125; 其中 handleRegistration方位是将新服务注册的事件传播出去，然后调用父类中的register方法，将InstanceInfo中的元数据信息存储在一个两层的ConcurrentMap中，第一层的key是 appName.,第二层的key是 instanceId,也就是说同一个服务名可以对应多个服务Id,id默认采用主机名实现不同，这使得无法在同一主机上启动多个相同微服务实例，spring cloud 对原生的Eureka InstanceInfo 实例做了优化，默认生成id会采用如下优先级规则： ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}} 相关的客户端配置属性为: 下为配置实例id为应用成名+随机整数区分、 eureka.instance.instanceId=${spring.application.name:${randon.int}} 调用时按照一定的策略去调用。]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发相关]]></title>
    <url>%2F2018%2F07%2F14%2F%E5%B9%B6%E5%8F%91%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[并发模型并发系统可以采用多种并发编程模型实现，并发模型制定了系统中对作业的协调和分配，不同的操作系统有不同的分配方式，同时线程间的协作和交互方式也不同，故效率也有所不同. PPCPPC(Process Per Connection): 每次有新的连接就新建一个进程专门处理这个连接的请求。父进程通过预先fork 子进程，在子进程里处理连接的读写请求和业务操作。进程创建占用内存资源高，父子进程通信复杂，连接关闭需要所有父进程中的子进程都关闭才能正确的被关闭。 TPCTPC (Thread Per Connection): 每次有新的连接就新建一个线程专门处理这个连接的请求，共享进程内的内存空间，线程间的通信方式也更简单。高并发是还是存在性能问题，线程间的共享和互斥会导致死锁问题，某一进程中的线程异常会导致进程直接退出。 ReactorPPC模式最主要的问题就是每个连接都要创建一个进程，连接使用完毕就被销毁，进程也被销毁，没有考虑到复用，Reactor模式，也成为反应堆模式，采用了池化技术，建立进程池，将连接分配给进程池里的进程，一个进程可以accept多个来自客户端的连接。并且对连接的数据处理做了优化，采用IO多路复用技术，提高了IO的利用效率，意思是将进程连接中的数据处理转变为非阻塞的，只有当一个连接有数据需要处理时进程才会去处理，一个进程不会一直阻塞在某一个连接的业务处理数据上。 SynchornizeJava对象头和moniter Java对象头 Java对象头是指在虚拟机中存储对象相关的一些信息，其中就包括synchornize 持有的对象锁；Java对象头包括两个部分，Kclass Pointer (类型指针) 和MarkWord(标记字段)，类型指针指向内存中类元数据，MarkWord 用于存储对象运行时的数据。 MarkWord 存储的对象的运行时数据包括哈希码，GC分带年龄，锁状态标志，线程持有的锁，偏向线程id（偏向锁），偏向时间戳等 Kclass Pointer 虚拟机通过这个指针来确定某个对象是那个类的实例 MointerMoniter为一个同步工具，同时也是一个对象,Moniter是线程私有的数据结构，每一个线程都会有一个可用的 moniter record(监控记录表)，每一个被锁住的对象都和一个moniter相关连，moniter中的某个字段存储拥有该锁的该线程相关的东西，如该线程ID。 基于Synchornize的锁优化jdk1.6以后对Synchronize这种锁实现了大量的优化选项，如自旋锁，适应性自旋锁，锁消除，锁粗化，偏向锁 轻量级锁等技术来提高锁的性能，减少对性能的开销。 锁的状态（从低到高）:无锁态-&gt;偏向锁态-&gt;轻量级锁态-&gt;重量级锁态。 自旋锁 线程的阻塞和唤醒状态的切换需要CPU从用户态（CPU较低特权-用户空间）转化为核心态（CPU较高特权-底层），同时，大多数应用线程对锁的持有都是短时间且频繁的，这种频繁的切换势必会导致CPU负载的提高和性能消耗（态的转化），自旋锁的出现就是为了解决这种问题，自旋锁就是让线程等待一段时间（执行一段时间无意义的代码），不会被立即挂起（进入阻塞状态），这是以占用CPU的执行时间片为代价的（CPU的并行时间片处理方式），但是如果有些线程持有的自旋锁迟迟不肯释放，就会白白浪费CPU的执行资源，所以，自旋不能完全代替阻塞，只能说在某些场景上，比较适用，我们需要定义一个合适的自旋等待时间（自旋次数决定），如果超出这个时间还没释放锁，就可以认为这个线程不适用适用自旋锁，应该改用立即挂起（线程阻塞方式）来持有锁。 锁消除 JVM基于对变量的逃逸数据分析（？），会消除无用的锁，既如果锁中的代码不存在共享变量和竞争，这种锁有时候不是显示的，有时候是隐式的，如Vector.add方法，StringBuffer.append()方法等等， 锁粗化 对于频繁的在一段代码内进行加锁，去锁的操作，会导致更多的cpu消耗，这时，使用锁粗化技术放大加锁的范围，减少加锁的次数可以明显提高性能。 轻量级锁 轻量级锁是由偏向锁转化而来的（可以认为他是比偏向锁的一个稍重的备份锁），轻量级锁的使用是在没有多线程竞争的情况下 ，减少重量级锁的性能消耗过大情况，每次获取锁，释放锁的操作依赖于底层多次CAS操作 重量级锁 重量级锁通过对象内部的Moniter对象实现的，本质上依赖于操作系统的Muter Lock指令实现 Volatile 定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。 volatile 可以保证变量对线程的可见性，被volatile 关键字修饰的变量，Java可以确保此变量对于所有线程来说，同一时刻，他们get到的都是相同的值，并且对该变量的更新，也会让所有的线程都知晓，表现为所有线程都能获取到此变量的最新的值。 volatile 无法保证复合操作的原子性，Java中基本数据类型的操作是原子性的. votalile 可以禁止指令重排序，volatile禁止重排序的实现是通过底层的内存屏障（lock前缀指令，一系列的指令）。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud微服务实战-1]]></title>
    <url>%2F2018%2F05%2F02%2FSpringCloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[记录学习Spring-Cloud的中Eureka集群的问题在Eureka单节点的配置文件: application.properties: server.port=8081 eureka.instance.hostname=localhost eureka.client.register-with-eureka=false eureka.client.fetch-registry=false eureka.client.service-url.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/ 另外，在pom文件中需要加入Eureka相关的starter POMs,需要指定Spring-Cloud的版本号，此处使用Edgware.SR3（埃奇韦尔-伦敦一地铁站名字）版本号， &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR3&lt;/spring-cloud.version&gt; &lt;/properties&gt; ..... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; .... &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 之后在Spring-boot的主启动文件Application.java类的定义头上加入@EnableEurekaServer注解即可，启动应用程序，单机Eureka注册中心即建立完成，访问localhost:8081可查看Eureka注册中心的Web详情页。(2) Eureka server集群的建立原理是将自己作为服务向其他服务注册中心注册自己，这样就可以形成一组互相注册的服务注册中心集群，但是服务注册信息不会进行二次链式循环传播，即1注册到2,2注册到3,3注册到1，这种，服务在1注册的不会同步到3上，这在PeerAwareInstanceImpl类中体现。Server集群可在原有的单机项目基础上进行改建，只需增application-peer1.properties,application-peer2.properties,application-peer3.properties,三个相关的配置文件，并将原application.properties中的两个选项： eureka.client.register-with-eureka=false eureka.client.fetch-registry=false 两项false改成true,或者注解掉.因为默认是true,这两项配置的意思是是否允许Erueka server注册自己,是否检索服务。application-peer1.properties文件如下： spring.application.name=eureka-server server.port=8081 eureka.instance.hostname=peer1 eureka.client.serviceUrl.defaultZone=http://peer2:80822/eureka/，http://peer3:8083/eureka/ 其他两个文件与此文件类似，改写即可，然后在通过java -jar *.jar –spring.profiles.active=peer1，….. 命令分别启动三个服务注册中心应用，另:–需要提前在hosts文件中为每个分片配置地址解析 ： 127.0.0.1 peer1127.0.0.1 peer2127.0.0.1 peer3 在命令行中执行上述启动命令后，可能会报如下异常： 即连接超时Exception,这种状况是正常的，因为在你启动一个注册中心后，另外两个注册中心还没启动，此时尝试连接这两个，当然会连接超时。在所有注册中心都启动后，日志信息会正常输出。至此，Eureka Server高可用集群搭建完毕。]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go基础实战]]></title>
    <url>%2F2018%2F05%2F02%2FGo%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Go语言基础Go（Golang） 作为一款Google 内部推行的开发语言，有很多其优点值得进行学习，下面是一遍基础的语法和实践，帮助认知和学习它. 一个Go 文件可以直接被运行，命令是：1go run main.go 但是Go 还是一门编译性语言，所以他的编译过程是存在的，编译命令为:1go build main.go Go的安装在Linux(CentOS)或者MacOS上都比较简单，在Windows上需要下载解压包，如：go1.11.2.windows-amd64.zip，官网下载，需要翻墙或者国内镜像，安装完成后，需要配置环境变量，*nix或者mac需要配置~/.bashrc文件，将export GOPATH=你的go的工作空间的位置缀入文件末尾即可。但是在win上，要配置GOROOT此项环境变量，如下图: .png) Go中的变量，变量声明方式有三种，分别是： 123var i int = 0var i = 0 i := 0 其中在循环判断中只能使用第三种变量声明方式，另外，全局变量建议使用第一种声明方式，局部变量使用第二种声明方式即可。 Go的循环语句只有for ,并且for的循环判断不需要括号，常规的循环中断也是支持的，包括 continue和break ，当然还有goto，当然goto 的建议用法是，不要用来控制流程中转，但是用到循环中断是可以的。其他的if else 判断也不需要括号，swtich 提供了两种方式的匹配，一种是值匹配，一种是表达式匹配： 1234567891011121314//第一种，值匹配switch x &#123;case 1: return 1default: return ""&#125;//第二种表达式匹配switch &#123;case param &lt; x : return ""default: return ""&#125; Go中的数据结构的数组有两种形式，一种是常规的静态数组，长度固定，类似Java。一种是切片，提供了灵活的长度变更的动态数组。数组变量的定义其实类似普通变量的定义，如：var arr [10]int, var arr [10]int = [10]int{1，…10},var arr = [10]int {1,…10 }, c:= [10]int{1,2,….10}]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql实战]]></title>
    <url>%2F2018%2F04%2F28%2FMysql%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Mysql的一些重要知识点 Mysql 分为Server 层和存储引擎层 server层： 连接器：连接器负责跟客户端建立连接，获取权限，维持和管理连接。 缓存层：链接建立后，mysql首先进行缓存层的查询（查询语句+结果形式的缓存），如果缓存层没有此结果，则进行下一步。但是，查询缓存的失效率很高，只要对一个表有更新，此表上所有查询缓存都会被清空，所以，查询缓存的使用场景是在静态表上（不经常进行更新操作的表，如系统配置表），mysql关闭查询缓存的参数是：query_cache_type = DEMAND,而对于显示指定查询缓存的命令是 select SQL_CACHE from T where ID=1;*。 分析器：做sql 语句的词法分析（将关键字和字段名，表名识别出来）和语法分析（sql的固定语法模式匹配)。 优化器：进行索引选择 执行器：查看对表是否有查询权限，若有，则执行真正的存储引擎提供的查询接口的调用. Mysql中的bin log 和 redo log WAL（Write Ahead Logging）技术：先写日志，在写磁盘（EX:在更新一条记录的时候，InnoDB引擎会先把记录写到redo log中，并更新内存，在引擎空闲的时候，会将这个更新记录写到磁盘上）。 redo log : 在InnoDB存储引擎中是固定大小的，redo log文件借助两个指针不断移动保持着记录的书写和擦除。redo log 可以保证数据库的crash_safe，即一但数据库发生异常重启，数据库也能从redo log 中恢复所有已经提交的记录。参数：innodb_flush_log_at_trx_commit = 1，表示每次事务的redo log 都持久化到磁盘上， (默认开启) redo_log 写入磁盘的时机：（1）当redo_log 满载的时候，系统停止所有的更新操作，将擦除指针进行推进，以便于redo_log腾出空间继续进行日志的记录。（2）当系统内存不足时，无法申请新的内存页来进行redo_log的flush操作。（3）当系统空闲时。（4）Mysql正常关闭的时候。 bin_log：bin_log是MySQL Server层独有的日志系统，即归档日志系统（bin log）,bin_log是逻辑日志不同于redo log是物理日志（直接书写在文件上），逻辑日志类似于“给字段X加上1这种”、binlog 没有固定大小，可以一直追加文件的形式增加。参数：sync_binlog =1 表示每次事务的binlog 都持久化到磁盘上（默认开启）。bin log 和 redo log使用二阶段提交协议来保证整个数据的更新不会存在数据一致性问题，因为 Server层和存储引擎可以看做是两个不同子系统的交互。同时，数据的一致性也保证了数据备份恢复的一致性。 事务： 隔离级别（读未提交，读已提交，可重复读，串行化）： 隔离级别的实现是通过 一致性读视图（consistent read view） 这种方式实现的，在可重复读(ReapeatableRead)级别下，视图在事务启动时候创建，整个事务存在期间都用这个视图，在读已经提交(ReadCommit)的级别下，视图是在每个sql开始执行的时候创建的，其余两种隔离级别没有使用视图的概念实现。更改数据库隔离级别的参数为 ：transaction-isolation = READ-COMMITED。 可重复读隔离级别的具体实现：Mysql 中的每条更新记录都会同时记录一条回滚记录(undo_log)，记录上的最新值，都可以通过回滚记录回滚到上一个状态，同一条记录在系统中可以存在多个版本(row),每个版本有自己的row_trx_id，就是数据库的多版本并发控制（MVCC）. 普通查询：一致性读视图有4种情况来确定当前版本的可见性： 如果是自己的事务的更新，则可见最新的记录 其他版本未提交，当前事务的一致性读视图不可见其他事务最新版本的数据，只可见小于当前版本row_trx_id的版本数据（需要通过undo-log回滚才能可见）。 其他版本已经提交，且在当前事务创建之前提交的，当前一致性读视图可见其他事务最新版本的数据， 其他版本已经提交，但是在当前事务创建之后提交的，当前一致性读视图不可见其他事务的最新版本的数据。只可见小于当前版本row_trx_id的版本数据（需要通过undo-log回滚才能可见）。 更新：更新数据都是先读后写，这个读不是一致性读视图中的读的情况，是另一种读，读的是最新版本的值，这称为当前读 当前读会拿到最新版本的数据,然后进行更新，版本是在记录被更新完后立马生成的。 事务的启动方式： 显示启动事务语句:begain 或者 start transcation ,commit,rollback …… set autocommit=0; 这个命令会将这个线程的自动提交关闭，直到你手动提交commit,整个事务进程才算结束。所以，如果你又是使用的长连接，回导致该事务演变成长事务，长事务会阻塞锁，并导致数据库视图回滚段资源一直得不到释放。因为建议将 set autocommit = 1 这样设置，打开自动提交，避免演变成长事务，在需要事务的时候，通过显示指明事务语句-begain来开启一个事务，并通过commit work and chain 提交当前事务，且开启下一个事务。 索引： Innodb 索引模型，在Innodb中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。每一个索引在Innodb 里面都是一颗B+树。 索引类型分为： 主键索引(聚簇索引)：叶子节点存储的是整行的内容。 非主键索引(普通索引，二级索引)：叶子节点存储的是主键的值。 唯一索引: unique key 全文索引 数据页：Innodb的数据是按照页为单位来读写的，当读取一行记录时，是将此行所在的页为整体读入内存，页的大小为16kb,在使用普通索引和唯一索引的选择上，尽量使用普通索引，因为大多数场景下，普通索引的性能都比唯一索引好一些（原因在于更新时，在数据也不在内存中时，唯一索引需要把记录所在页的数据从磁盘中读入内存，然后进行计算是否唯一，磁盘到内存会导致随机IO访问，极大耗费资源，少部分情况是如果更新数据后需要马上查询，这种情况使用普通索引和唯一索引没什么区别，但普通索引会有一个change buffer 的merge操作，会耗费Buffer pool等资源，建议将change buffer关闭。） 索引的维护： B+树是一颗平衡N叉树，所以为了时刻维护平衡性，在对索引更新时（插入，删除，更改），有空间利用率（页分裂）和性能的问题，主要是主键索引保持顺序性，这时候，如果可以使用自增主键，则主键的更新就不会对索引产生太大的影响，从性能和空间上来看，自增主键比较好用，但是有些场景适合使用业务字段做主键，比如说，在一个表中只能 使用一个索引的情况下，且该索引必须是唯一索引，这时候，就可以使用该业务字段当主键并绑定索引。 索引使用： 覆盖索引，即查询的字段 = 索引，不访问其他列的数据（不会回表）。 全值匹配，和索引中的所有列进行匹配。 最左前缀匹配，利用B+树的特性，对于联合索引，只有查询的字段符合联合索引定义的顺序（不用使用联合索引中的全部字段），即可使用该联合索引，加快查询速度。总结来说就是联合索引左边N个字段，也可以是字符串索引的最左M个字符。 匹配范围值，对于VARCHAR，BLOB,TEXT类型的索引，必须使用前缀索引（规定），但是需要考虑重复性，而且使用前缀索引会使Order by 和 Group By无法使用该索引（失效）。Mysql 不能再索引中使用通配符+LIKE+通配符的操作，但可以使用满足最左前缀原则的LIKE操作，原因是会将这个LIKE操作转化为比较简单的比较操作，这是底层存储引擎API的限制。索引的选择性：不重复的索引值（也称呼为基数）和数据表的记录总数T的比值，这个比值的范围在1/T到1之间，索引的越高，则代表索引的查询效率越高。唯一索引的选择性是1。索引排序使用：只有当索引的列顺序和ORDER BY子句的顺序完全一致（最左前缀），并且ORDER BY后所有要排列的列的方向都一样时，可以使用索引进行排序，如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表的字段时，才能使用。当前导列为常数项时。也可以进行查询排序操作。 锁： 共享锁：一旦锁定任何其他客户端都不可读写，加锁的客户端可以进行读操作，但不能进行写操作。 排他（独占）锁：只有加锁的客户端可读可写，其他客户端不可读不可写 全局锁： 对整个数据库实现加锁： 命令是 Flush tables with read lock,此命令会使整个库处于只读状态。客户端断开连接的时候或发生异常的时候回主动释放该锁，此锁的使用场景是全库备份。 表锁（表锁和元数据锁）： 对整个表实现加锁：命令是lock tables tableName read/write。 解锁命令是 unlock tables tableName read/write，其中read是共享锁，锁定后，任何客户端都不可读写；write是独占锁，只有加锁的客户端可读可写，其他客户端不可读也不可写。 元数据锁：元数据锁是被隐式使用的，当对一个表进行增删改查擦操作时，会先加MDL(元数据)读锁，当要对表结构做变更操作的时候，默认会先加MDL写锁。MDL读锁之间不互斥，因此增删改查可以多线程并行操作。MDL写锁和MDL读锁、MDL写锁互斥，因此表结构变更和表操作不能同时进行。问题：MDL锁会在事务结束之后才释放，因此，如果有一个长事务在此表上，很可能会造成数据库崩溃现象（线程访问过载），解决方法：在DDL表结构变更语句后设定等待时间（alter table ……times）,此段时间内如果没有拿到MDL写锁，就不执行变更，然后过一段时间DBA在重试这个过程。 行锁：针对表中的行记录的锁，innodb的行锁，是一个范围锁，根据条件锁定部分范围，而不是映射到具体的行上，因此它又叫间隙锁。Innodb事务中，行锁是被隐式加上的，行锁的释放时间是当事务被提交以后 这是两阶段锁协议。如果事务中有多行锁需要并发的更新，把更新频率最频繁的行放到末尾，减少行持有锁的时间，增加并行度。select from where &lt;条件&gt; Lock in share mode,对查询的记录添加共享锁。select from where &lt;条件&gt; For update,对查询的记录增加排它锁。 死锁和死锁检测： 线程出现循环依赖，互相等待释放彼此持有的资源，就会造成死锁现象，当数据库中出现行死锁现象后，Innodb有两种处理方式： 一种是直接进入等待超时，参数设置 innodb_lock_wait_timeout。 另一种是发起死锁检测（消耗CPU资源），发现死锁后，主动回滚死锁链条中的一条事务，让其他事务得以继续执行，参数设置innodb_deadlock_detect = on。 必要使用数据库中间件做并发度控制（性能考虑），才能适应热点行的并发更新。 当遇到插入过程非常缓慢的时候，比如插入10万调数据需要大约半个小时这种，可能是Mysql 默认开启了innodb_flush_log_at_trx_commit 和sync_binlog这两个参数，]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql安装问题]]></title>
    <url>%2F2018%2F04%2F28%2FMySql-For-Windows7-Regedit-service-error%2F</url>
    <content type="text"><![CDATA[记一次Mysql注册服务相关问题mysql解压版本的正确启动： 需要配置环境变量，环境变量的配置建议在系统Path中配置，配置完bin目录后. 需要配置默认的my-default.ini配置文件，主要就是设置字符编码和basedir和datadir两个配置选项，分别为mysql的解压目录和mysql的数据存储目录，数据存储目录需要我们手动在mysql的根目录下建立data文件夹 初始化mysql命令:mysqld –initialize-insecure –user=mysql 注册mysql服务：mysqld –install mysql服务名（可自定义）–defaults-file=”mysql配置文件的路径”，注意，此处注册的mysql的配置文件不可以用其默认的my-default.ini，必须另外建立一个该文件的副本如my.ini,否则会导致服务启动失败，如下图所示：]]></content>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试知识点整理-1]]></title>
    <url>%2F2018%2F04%2F28%2F%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86-1%2F</url>
    <content type="text"><![CDATA[JAVA基础部分：final,finally,finalize区别： final可以修饰方法，类，成员变量，当final修饰基本类型的成员变量时，该成员变量的值不可变，当fina修饰引用变量时，改引用指向的对象实体不可变，但是对象实体中的内容可变。当修饰类时，final和abstract不可同时使用，abstract意指该类是抽象的，用于扩展的。final修饰类时则意味着该类是不可被继承和扩展的。修饰方法时，该方法不可被重写。修饰形参时，该形参不可在方法内被重新赋值。 当方法内有定义内部类或者内部匿名类时，该方法的成员变量必须被final所修饰，因为在成员内部类中可能会修改该成员变量的值，这扩大了该变量的范围，造成安全隐患。 finally一般用在try catch 后，无论程序是否抛出异常，必定会执行finally中的语句块，一般用于IO资源的释放，或者连接资源的释放。 finalize是Object中的一个方法，用于资源回收。Exception,Error： 都继承自Throwable，error属于非受检类型，一般是底层资源错误或者系统错误 Ex:栈溢出,或者OOM(堆内存溢出)，不能在应用代码级别被处理. Exception分为 RuntimeException(运行时)和其他Exception（编译时）,RuntimeException也属于非受检类型，通常指应用程序运行中出现的bug导致的，Ex:NullPointerException,ArrayIndexOutOfBoundException,ClassCastException,IllegalStatementException其他Exception属于受检类型，编译时异常如 IO Exception。异常的处理方式：提倡提早捕获，延迟抛出。出现异常时，若可以解决则捕捉，不能解决则抛出。Session和Cookie: cookie和session都是一种客户端和服务端会话保持技术， 由于Http是一种无状态的协议，cookie有 version0和version1两个版本，两个版本的差别在于 set-cookie2响应头的属性项多了一些，在JavaWeb的Servlet规范中不支持Set-Cookie2这种响应头，但是在实际应用开发中我们却可以使用Set-Cookie:响应头里设置Set-Cookie2属性项。cookie可以让服务端程序跟踪每个客户端的访问，但是每次客户端的访问都必须回传这些Cookie,如果Cookie很多，会加大服务端和客户端的带宽等消耗，另外，不同的浏览器对cookie的数量和大小都有限制，session可以解决这些问题。 基本上大多数session都是基于cookie来工作的，第一次客户端访问应用时会生成一个JSESSIONID,此ID对于每个客户端是唯一的，然后通过Cookie回传到客户端，等下次访问服务器时，就携带者这个Cookie,根据这个Cookie的Id会检查服务器中的Sessiond对象是否存在，不存在就创建，存在就设置值，并将这些生成的session对象放置到SessionManager容器中管理，这个容器将管理所有session对象的生命周期，这就是session的会话保持技术。 分布式环境下Session的共享问题，分布式环境下，因为cookie储存在客户端浏览器中，每次访问不同的服务器都会携带会话状态信息，所以不存在不同服务器会话不一致问题，但是会有其他的问题，比如说，大小和数量限制问题导致的Cookie丢失，安全问题，cookie窃取，虽然可以设置HttpOnly属性防止私密Cookie被访问（加密Cookie,维护问题）。Session的共享需要放置在分布式缓存当中，MemCache集群，Tail等，分布式缓存框架的实现：重新实现HttpSession接口，定义自己的Session操作类，这个操作必须在进入应用之前完成，所以需要一个拦截器Filter拦截进入Mvc框架之前的请求，并封装HttpRequest和HttpResponse,然后根据SESSIONID获取到用户的私密信息（从分布式缓存中获取），然后将我们自己定义的Session对象设置到request和response对象中，最后将最新的会话信息保存到分布式缓存中。 BIO和NIO: BIO:同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。 NIO:同时支持阻塞与非阻塞模式，但这里我们以其同步非阻塞I/O模式来说明,selector(多路复用器)不断轮询IO的状态，只有在channel有Buffer可读或者可写时，应用程序才去处理它，在线程的使用上，就不需要一个IO请求对应一个处理线程了，而是在确实是需要进行IO操作是，才会使用一个线程去处理，这样避免了BIO模型下大量线程处于阻塞等待的情景。相对于BIO的流，NIO抽象出了channel作为输入输出的通道，并且提供了buffer的支持，在进行读操作时，需要使用buffer分配空间，然后将数据从channel中读入Buffer中，对于写操作，需要将数据写入Buffer中，然后将buffer写入Channel中 HashMap: HashMap1.7 :给定的默认容量是16，负载因子为0.75，map在使用过程当中当元素容量达到了阈值时即负载因子*默认容量时，开始进行扩容操作，扩容操作是一项非常耗费性能的操作，需要进行rehash,数据复制等操作，建议提前预估HashMap的大小，减少扩容带来的性能损耗，Entry[]即table, put方法解析： 判断当前数组是否需要初始化，如果Key为空，则puty一个空值进去， 根据Key计算出hashcode，根据计算出的hashcode定位出所在的桶，即数组的索引， 如果对应索引的元素（Entry）是一个链表，则需要遍历判断里面的hashcode,key是否和传入的key相等， 如果相等则进行覆盖，如果该索引处的元素为空，说明当前位置没有数据存入，直接新增一个Entry对象写入当前位置 jdk1.8:put方法(): 首先初始化table是否为空，如果为空则在resize()方法中进行初始化操作， 然后计算该key（根据hash值）在table中的索引位置，如果该索引处的桶为空，则没有发生冲突，直接在此位置上new一个新桶即可。 否则则比较当前桶的key和hash是否和传入的key和hash是否相等，相等就赋值给e,后续会进行覆盖操作， 上面条件若不成立则会进行判断是否是树节点，如果是红黑树，则按照红黑树的方式进行put. 上面两条件若都不成立，则进行判断是否为链表，若是，则遍历链表，查看是否有和传入的key相同的链表元素存在，查找到会结束循环.否则则在该 桶后append链表元素。当链表的长度达到转变为红黑树的阈值时，将链表转化为红黑树，结束循环。 如果e不等于null,就相当于存在相同的key,那就需要将值覆盖，最后判断是否需要进行扩容. Integer和int（包装类和拆箱，装箱）: Integer是int的包装类，基本类型都有包装类，包装类能自动转化成相应的基本数据类型，称为拆箱，如包装类做算数运算时，反之（new Integer(1)），称为装箱。装箱和拆箱的设计是一种享元设计模式（它使用共享物件，用来尽可能减少内存使用量以及分享资讯给尽可能多的相似物件）,在装箱的时候，对于在-128到127的int值，Integer会从IntegerCache中拿到相应的复用对象。当大于127时，会重新new一个Integer对象。StringBuffer,StringBuilder,String: String的具体实现为 final char value[],他是immutable的（不可变对象），不会存在多线程访问的安全问题，但是性能会有所降低，所以提供了一个可变对象StringBuffer,由于考虑到多线程并发访问的问题，StringBuffer被设计成了Synchronized修饰的，1.5以后，为了提升StringBuffer在单线程下的性能，引入了StringBuilder，StringBuilder和StringBuffer的方法相同，当做字符串连接 ‘+’的使用被编译器所优化，直接在编译期生成一个String对象，如果该对象对象的字符串变量在常量池中已经存在，那么用+ 比用StringBuffer或者StringBuilder都要快，; 重载：在同一个类中，有多个方法名相同，形式参数列表不同的方法，与修饰符无关，与方法的返回值无关。 重写：子类重写父类方法，只有实例方法可以被重写，静态方法不可以被重写，重写的方法签名相同，但访问权限必须大于等于父类的方法，异常是夫类的子类，返回值必须小于父类的返回值，修饰符可以随意更改。 抽象类和接口：抽象类的目的是对根源的抽象，因为在Java中的单继承中只能继承一个抽象类，在这个抽象类中，你必须抽象或者实现所有可能子类要用的方法，但是接口是对动作的抽象，当你关注一个具体的操作时，使用接口。接口中的变量都是static类型的，而抽象类不是。 反射：反射的用途，用于在运行时获得一个类的具体内容或者调用一个类的方法，实现：JDK中的动态代理使用了反射(在运行时调用任意一个被代理类的方法，生成动态代理)Get和Post的区别： 表面上有以下几点不同，get是有缓存的，post没有，get可以刷新和回退，post需要重新提交表单，get对数据长度有限制(url最大2048)，而post时没有数据长度的限制。 安全性：post比get更安全，get请求里的所有数据都会显示在URL里，Post的参数不会被保存在浏览器上或者Web服务器日志上。 但从本质语义上的区别时：Get的语义请求是获取指定的资源，它是，安全，幂等，可缓存的，get方法的报文主体没有任何语义，Post是根据报文主体对指定的资源进行处理具体的处理方式视资源类型不同而不同。MVC设计思想： MVC(model view controller)模型视图控制器模式：一种设计模式，在软件系统的设计中，展示层也被称为视图层，是給用户展示和交互的页面，视图层只是数据的输出终点，并没有真正的业务处理。而在 模型层中是一个数据规范，模型和视图具体的数据格式无关，所以他可以被应用在多个视图当中，这减少了代码的重用性，控制器接受用户的请求并操纵模型和视图去完成用户的需求，他会决定去操纵那个模型构件去处理请求并返回到指定的视图。equals和==： 对于String类型的引用对象，equals比较的是对象在堆中存储的实际内容，而==则比较的是这个对象的句柄引用，对于基本数据类型的对象，==比较的是值,equals不能比较基本数据类型，而对于其他引用对象，==和hashcode（默认继承的是Object中的hashcode方法）则比较的是对象在内存中的句柄引用。 hashcode和equals的方法的区别和联系：hashCode和equals两个都是比较对象是否相等的，重写的Object的equals方法比hashCode更严谨和全面，所以效率就比较低，但是hashcode方法虽然效率高，但是hash算法无法保证每个不同对象生成的hash值不同，既冲突，这是其不可靠的一面。同时。hashcode规范是：一个没有改变的对象调用equals方法时如果相同，则其hashcode方法比较的也必须一致，反之，如果两个对象的hashcode方法得到的唯一散列值一致，则这个对象的equals比较的结果不一定相同。值传递和引用传递： Java中不存在真正的引用传递，所谓的引用传递和值传递都是指方法调用时参数的传值策略，而不是传递的内容（值或者引用）的类型，至于值类型和引用类型是区分内存分配的两种方式。函数的值传递会创建一个传入对象的副本，所以无法改变原有对象，在引用传递中，则不会创建副本，所以会改变传入的原始对象。在Java中，函数参数的传递方式是值传递，传递的值是引用。JAVA中常见集合部分：Collection: ArrayList:实现了基于动态数组的数组结构，默认长度为0，最大长度为Interger最大值-8，当数组长度超载时，每次增幅50%，因为内存中储存的地址连续，所以查询效率会比较高，删除和添加效率较低。 LinkedList:基于链表的数据结构，地址是任意的，所以在插入或者删除的时候，内存中对于地址的操作较为轻松。 HashSet：哈希表实现的，其中的数据是无序，不可重复的，根据hash函数区别重复元素可以放入null. LinkedHashSet：哈希表实现的有序，不可重复的集合。 TreeSet：二叉树实现的，有序的，不可重复的，不允许存储null值 Map:HashMap,ConcurrentHashMap 并发和多线程： 生产者和消费者模型： 可见性：当多线程的共享变量发生变化时，其他线程能看到变化后的值， 重排序：编译器或者cpu会在不改变单线程代码语义的前提下对代码的执行顺序进行优化，这可能会引发线程不安全。 原子性：对变量的操作具有不可分割性。 Synchronized和Lock:Synchronized是 Java内置的一个特性关键字，Lock是一个接口，Synchronized在发生异常时会主动释放锁，Lock需要主动调用unLock()方法来释放持有的锁，但是Lock可以让阻塞等待的线程响应中断，而Synchronized会一直阻塞下去（死锁），如果线程之间并发争抢资源不严重，Synchronized的性能比Lock要好，反之，则Lock的性能比较好。公平锁：等待时间长的线程优先获得锁。 wait和sleep的区别：每个对象都持有一个内部moniter对象，JVM会为每个对象维护两个“队列”，分别是EntrySet和WaitSet.EntrySet用于存储等待获取对象的内部moniter的所有线程，而waitSet用于存储执行了obj.wait/wait(long ms)方法的所有线程。sleep()方法属于Thread类，wait()方法属于Object类，sleep会导致当前线程让出cpu的使用权到指定的时间，期间仍然会保持对锁的监控状态，所以，调用sleep方法并不会释放线程所持有的锁，而wait方法会放弃该线程持有的锁对象，进入waitSet，此时线程状态为BLOCKED状态。当使用notify唤醒该线程时，线程状态标记为RUNABLE状态,线程进入EntrySet中和其他活跃线程争抢锁的持有权。 单机事务：事务的核心是锁和并发，四大特性是指原子性（Atomic）、一致性（Consistency）,隔离性（isolation）和持久性（duration）.2PL:数据库中的update,insert,delete都是先读后写的方式。处理事务常见的方式有排队法：单线程序列化读写，不需要冲突控制，但是对于硬盘一类的慢速设备性能较差，对于redis一类的内存数据库，内存和单个cpu绑定，针对此内存块的数据的读写操作都是在单个cpu上完成，既没有线程上下文切换的时候速度是最快的。对于慢速设备需要使用多线程和异步的方式对请求进行批量缓存提交，线程和请求之间没有绑定关系。排他锁：对事物之间的共享数据进行锁，完成数据库系统的访问控制。事务之间的调优原则是：尽可能减少锁的覆盖范围，表锁变行锁，增加锁上可并行的线程数量如：读锁和写锁，读写线程分离。并行读取数据，选择正确的锁类型：悲观锁适用于并发争抢比较严重的场景，乐观锁适合不怎么严重的场景。 分布式事务：分布式事务指的多个微服务之间的事务不一致导致的数据一致性问题。解决的办法最常用的是oracle 的xa二阶段提交协议，第一阶段，有一个协调中心节点向所有参与事务节点进行询问请求，所有参与节点进行各自事务相关的数据更新，并将更新日志写入undo log或者redo log中，用于提交或者回滚。当所有的参与节点返回成功给中心调节节点的时候，开始执行第二阶段，第二阶段，协调中心向所有参与者发送让他们commit的请求，所有参与者进行本地事务的提交，提交成功后，返回完成消息给中中心节点，，分布式事务完成。 并行是指两个或者多个事件在同一刻发生；并发是指两个或者多个事件在同一时间间隔发生； 进程是资源调度（指内存资源或者IO设备这种资源）的基本单位，线程是cpu调度的基本单位。 volatile是轻量级的synchronized,他在并发环境中保证了共享变量的可见性，并禁止重排序，原子性保证：但对复合操作（i++）或者long类型或者double类型的不行，因为那是两步操作。 内存可见性：Java线程之间的通信由Java内存模型控制。JMM决定了一个线程对共享变量的操作结果何时对另一个线程可见，每个线程独有的本地内存，本地内存中存储了共享变量的副本，本地内存是JMM抽象出来的一个概念，实际并不存在。JMM通过插入特定的内存屏障指令来禁止cpu级别的指令重排序。JSP-133规范采用happens-before的概念来阐述操作可见性，在JMM中，如果一个操作的执行结果对另一个操作可见，那么这两个操作必定要存在happens-before关系，这样的操作可以不同的线程之间或者同一个线程之内。 CAS(compare and swap)Atomicxxx类型的变量和Lock操作类的底层都是实现了此机制，对变量的操作涉及到3个操作数，内存中的值，变量旧的预期值，要修改的值。当要修改时会检查内存中的值和变量旧的预期值是否相同，如果不同，则认为提交更新失败，线程会自旋等待一段时间后重新计算当前内存值，和要修改的新值。CAS对cpu的要求比较高，且只能保证一个变量的原子性，且存在ABA问题。ABA问题：A线程修改了变量的值为另一个，B线程比较当前旧预期值和内存中的值是相同的，然后阻塞，线程C将变量的值从另一个变更为原来的值，然后B拿到锁，开始执行CAS步骤，又将变量的值重新更新为另一个。解决方法，对变量添加版本号的标识，每一次的更新都会对版本号做变化，更新前会对版本号做对比，不同则不能更新。 线程安全的定义（周志明）：当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替进行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么称这个类是线程安全的 框架部分： RPC:调用本地函数一样调用远程其他虚拟机内的函数，屏蔽了底层的传输方式和序列化方式，降低了服务之间沟通的成本，gRPC：google开源的一款语言中立的RPC框架，基于Http2协议（双向流，消息头压缩,单TCP的多路复用，服务端推送）,基于IDL文件定义服务。通过proto3工具生成指定语言的数据结构、服务端接口和指定语言的客户端Stub,序列化支持PB(protocal Buffer)和json,PB是一种语言无关的高性能序列化框架。 tomcat:tomcat作为一个jsp/servlet容器，有三种工作模式：独立的servlet容器，进程内的servlet容器，进程外的servlet容器。tomcat在不同工作模式下的请求分为两类。tomcat作为应用程序服务器，请求来自于前端的Web服务器.tomcat作为独立服务器，请求来自于web浏览器。 Spring Bean实例化的过程：先从配置文件或者 Java配置类或者注解中读取一个Bean的元数据配置信息，然后在Spring容器中注册这个（BeanDefinition）Bean的定义信息到专门的一个注册表上，IOC容器根据这个Bean注册表实例化Bean,然后将Bean实例放到 Spring 容器中（或Bean缓存池中（Singleton实例））。 BeanFactory：beanfactory是Spring的基础组件。它的主要方法是getBean(String beanName)，获取一个特定beanName的Bean实例，他通过其他接口和抽象类的扩展，完整了整个Spring容器实例化bena的一个过程，最终给开发使用的实现类是XmlPathApplicationContext和FileSystemApplicationContext,这两个Context都是BeanFactory的实现。Bean标签有两个重要的属性，分别是init-Method = “bean初始化的时候执行的方法”和destroy=method =”销毁方法”。 Spring-boot ：独立的Spring应用程序，嵌入的tomcat服务器，无需打包成war,简化Maven配置，自动配置Spring,提供生产就绪功能，如健康指标，监控点等。 JVM:类的加载过程 类加载过程的五个阶段：加载（加载二进制数据到内存中），连接(验证，准备，解析)，初始化（静态变量赋初值，常量赋值），使用（new()） 和卸载 (垃圾回收)。 加载：加载阶段时通过一个类的全限定名称来获取定义此类的二进制字节流，将字节流的静态存储结构转化为方法区的运行时数据结构，然后在内存（1.7方法区，1.8元空间）中创建代表此类的java.lang.class对象，并提供了访问方法区内的这个类的各种数据的入口。 类初始化时机（有且只有这五种）： 遇到new,getstatic,putstatic,invokestatic这4条字节码指令的时候（new 一个对象，读取或设置一个类的静态字段（被final修饰，已在编译器把结果放入常量池的静态字段除外））。 使用java.lang.reflec包的方法对类进行反射调用的时候， 当初始化一个类的时候，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main方法的那个类），虚拟机会先初始化这个主类。 使用JDK7动态语言支持时。 初始化：初始化阶段是类加载过程的最后一步，这一步会执行类中定义的Java字节码、可以这么理解，初始化阶段是执行类构造器方法的过程，方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，顺序是代码从上到下的顺序。另外类方法和类构造函数方法不同。此方法的使用是线程安全的，多线程并发争抢会被阻塞。类加载器 Sun JDK关于JVM监控和处理故障的命令: jps:JVM Process Status Tool:显示指定系统内所有的HotSpot进程(jps -l -m)jstat：JVM static Monitoring是用于监视虚拟机运行时状态信息的命令jmap:JVM Memory Map 用于生成heap dump文件，堆快照文件，一般用MAT工具进行分析，大对象无法被回收或者过多应该被回收的对象一直被引用。jstack:用于生成jvm当前时刻的线程快照，线程快照是当前JVM中每条线程的方法的执行堆栈集合，可以查询线程死锁或者循环等待等问题。jinfo:JVM Configure Info 用于查看和调整虚拟机的运行时参数，能看到更详细的，未被指定的参数。 linux 相关： cat[选项][文件]：查看文件内容，但是对于较大的文件不适合，会过多占用系统资源，无法进行交互和控制more[选项][文件]：分页查看文件、less[选项][文件]：更高级的查看和搜索文件内容的方式tail[-f（必要参数）][可选参数][文件]：查看文件的最后几行，一般用于日志文件的实时查看。head:查看文件的头几行。wc [选项参数][文件]：统计文件中字符的个数 架构篇数据库上万QPS如何支撑(16核32G)：（1）分库分表：正常情况下这种服务器的并发量一般控制在2000左右，百分之75-80的负载，分成五个库，每个库都有相同的表，表结构相同，表名不同，然后借助数据库中间件（Sharding JDBC or My CAT），考虑到分布式事务这种情况,使用hash算法按照数量取模得到库。进行查询和更新操作。（2）读写分离，从库同步主库的数据。保证数据一致性。（3)分布式唯一ID:SnowFlake 算法，64位Long类型数字，第一位无意义（取正整数 0），第2-41为表示时间戳，第42-52表示工作机器ID(5个机房ID,5个机器ID),第53-64：同一毫秒内产生不同的ID数量：2^12-1=4096个不同的ID. 数据结构和算法部分：]]></content>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ实战(1)]]></title>
    <url>%2F2018%2F02%2F21%2FRocketMQ%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;RocketMQ是一款阿里自主开源的分布式消息中间件，其没有完全遵循JMS(JAVA Message Services)规范，并且和常用的ActiveMQ相比，具有很多优良的特性，并且在如今高负载，大流量的业务场景下完全可以胜任。 RocketMQ原生支持分布式，不用像ActiveMQ一样做额外的配置，单点式消息中间件 RocketMQ保证了消息的严格顺序，ActiveMQ可能会有消息错乱。 丰富的消息拉取模式。 亿级消息堆积能力 &nbsp;&nbsp;&nbsp;RocketMQ的发布订阅模式规定了其采用了Group机制实现消息的负载均衡。即根据Topic的消息数，均衡分布到每个Group相应的数据量，其中Group可以是一台机器或者一个进程。 RocketMQ的集群部署 多Master模式多个Master存在的模式，当一个Master宕机的时候，会由于其他的代替，缺点是宕机的Master上的消息无法再被订阅，除非复活。 多Master多Slave模式（同步双写）适用于并发量比较大的情况下，只有Master/Slave都成功才能成功，相比于异步辅助，提高了强一致性，但是减缓了读写速度 多Master单Slave模式（异步复制）Master/Slave有短暂的延迟，高可用模式，Master宕机的时候，Slavek可以读到消息，但是可能会有少量的信息丢失。]]></content>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSE中的默认VM-HotSpot]]></title>
    <url>%2F2018%2F02%2F03%2FJavaSE%E4%B8%AD%E7%9A%84%E9%BB%98%E8%AE%A4VM-Hotspot%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;”hot spot”故名思意,就是热点的意思，在JVM的执行引擎中，热点又通常指执行频率高的代码，而执行频率高的评判标准则是有很多种表现，如方法的执行次数，或者某条执行路径的次数。HotSpot内部的执行引擎采用混合执行模式，即包括解释器和自适应编译器（Adaptive-compile）. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虚拟机的默认配置下，初始化时所有的Java方法都由解释器执行，解释器记录着每个方法的执行次数和循环次数，并以这两个指标去判断一个方法的”热度”。等到一个方法足够”热”的时候，JVM就会启动该方法的编译，这种在所有执行过的代码里只寻找一部分编译的做法，叫自适应编译，为了实现动态编译，执行引擎需要多层，且一定有一层是进程初始阶段的编译，然后再让自适应编译处理其中的部分代码。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JIT编译（Just-in-time）即每当一部分代码要第一次准备执行时，将这部分代码编译。同时JIT编译和自适应编译都属于动态编译的范畴，其特点是在程序运行的时候进行编译，而不是在程序开始之前就进行编译，和静态编译相互区分。而在HotSpot中的VM是使用”JIT编译的（动态编译）”。其中的Client Compile(C1)和Sever Compile(C2)通常被称为”JIT编译器”。]]></content>
      <tags>
        <tag>JVM</tag>
        <tag>JIT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作点滴0001]]></title>
    <url>%2F2017%2F08%2F16%2F%E5%B7%A5%E4%BD%9C%E7%82%B9%E6%BB%B40001%2F</url>
    <content type="text"><![CDATA[项目构建公司还在用svn,项目从里面checkout出来，然后ide导入本来是一件简单不过的事情，但是，但是，最后还是搞了一天，从侧面反映了自己这个农民工还是不熟练，详情如下。项目采用在IDE（eclipse）maven 导入的方式构建，经过漫长的jar包下载和配置文件Validation（后来才想起来该关掉这个……~.~），项目出现了3万+个errors,项目工程模块分的巨多，这也导致了问题排查的困难，一开始我也怀疑是maven配置文件的原因，最后真是，拿到了正确的配置文件，开心去替换了下，错误减少了点，而且剩下的大部分xxx cannot be resolved to a type这种错误，百度和google都试了一下，不得而解，最后试了某一个博客的方法，具体做法是： project-automatically 对勾给取消掉了，应该是防止自动构建用的选项， project-clean 项目clean 完毕,在progress视图里又看到了项目在自动构建（不解），可能会导致eclipse报错，栈溢出了（惊吓）。 项目右键，maven-update project,项目更新完毕，错误消失。 ###原因思考：网上的解释是eclipse和maven的clean并不同步（存疑解释）,另一种是因为某些特殊原因，eclipse没能自动编译(应该是maven生成的)源代码到build/classes（或其他classes目录），导致类型查找不到,(什么原因呢？) ###tips(项目执行这个命令会生成 mvn eclipse:eclipse 会自动生成相关的类文件，不需要在用maven 方式导入项目,以普通方式导入即可)。]]></content>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS[域名系统]基本解析]]></title>
    <url>%2F2017%2F06%2F27%2FDNS-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E6%9C%AC%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[DNS(Domain Name System)此协议根据域名解析到此域名对应的相应的ip地址，然后再来访问此IP地址对应得网站或者主机。首先，本机一定要知道DNS服务器的IP地址，否则上不了网，通过DNS服务器，才能知道某个域名的IP地址到底是什么,DNS服务器的IP地址，有可能是动态的，每次上网是由网关分配，这叫做DHCP机制，也有可能是事先固定的地址，一些公网的DNS服务器，也可以使用，其中最有名的就是Google的8.8.8.8和Level3 的4.2.2.2 过程采用了分级查询–域名的层级结构如下：主机名（这是用户在自己的域里面为服务器分配的名称，用户可以任意分配）.次级域名.顶级域名.root(根域名，默认是省略的)。每一级都有自己的NS记录（NameServer）此记录指向该级域名的域名服务器，此服务器知道下一级域名的各种记录。 DNS服务器内置了根域名服务器的NS记录和IP地址（这些记录一般是不会变化的，）根域名服务器全世界只有13台，分别是从A.root-servers.net到M.root-servers.net。 然后DNS服务器向所有这些根域名服务器的IP地址发出”0查询0“请求，询问索要查询的域名（如：www.douyu.com）的顶级域名服务器com.的NS记录，最先回复的根域名服务器将被缓存，以后只向这台服务器发送请求. 接下来，DNS服务器向这些顶级域名服务器发出请求，询问次级域名douyu.com的NS记录，返回了此次级域名的四条NS记录和其对应的服务器名称和IP。 最后，DNS服务器向这些次级域名发送查询请求查询。主机层www对应的NS记录，返回相应的主机服务器和其对应的IP.此IP即是我们要的结果IP。]]></content>
      <tags>
        <tag>tcp</tag>
        <tag>ip</tag>
      </tags>
  </entry>
</search>
