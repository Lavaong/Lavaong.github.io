<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[面试知识点整理-2]]></title>
    <url>%2F2018%2F11%2F02%2F%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86-2%2F</url>
    <content type="text"><![CDATA[学习笔记工厂方法模式中有一个问题，添加一个新的产品时，可以在客户端代码中直接通过xml+反射机制来生成产品对象，在定义产品对象时使用抽象类型，同样可以确保系统的灵活性和可扩展性，增加新的具体产品类无须修改源代码，只需要将其作为抽象产品类的子类再修改配置文件即可，根本不需要抽象工厂类和具体工厂类，这个答案应该是：创建对象与使用对象-工厂的作用-https://blog.csdn.net/will130/article/details/50446287 面试相关 Restful: Rest是一种设计原则，分为几个方面。(1),网络上的所有事物都被抽象为资源，每个资源都有唯一的一个资源标识符，同一个资源具有多重表现形式，所有的操作都是无状态的，符合Rest原则架构方式即可成称为Restful. 幂等性：对同一Rest接口的多次访问，得到的资源状态是相同的 spring的IOC和DI: https://blog.csdn.net/luoyepiaoxue2014/article/details/72426666 session共享问题: cookie和session都是一种客户端和服务端会话保持技术， 由于Http是一种无状态的协议，cookie有 version0和version1两个版本，两个版本的差别在于 set-cookie2响应头的属性项多了一些，在JavaWeb的Servlet规范中不支持Set-Cookie2这种响应头，但是在实际应用开发中我们却可以使用Set-Cookie:响应头里设置Set-Cookie2属性项。cookie可以让服务端程序跟踪每个客户端的访问，但是每次客户端的访问都必须回传这些Cookie,如果Cookie很多，会加大服务端和客户端的带宽等消耗，另外，不同的浏览器对cookie的数量和大小都有限制，session可以解决这些问题。 基本上大多数session都是基于cookie来工作的，第一次客户端访问应用时会生成一个JSESSIONID,此ID对于每个客户端是唯一的，然后通过Cookie回传到客户端，等下次访问服务器时，就携带者这个Cookie,根据这个Cookie的Id会检查服务器中的Sessiond对象是否存在，不存在就创建，存在就设置值，并将这些生成的session对象放置到SessionManager容器中管理，这个容器将管理所有session对象的生命周期，这就是session的会话保持技术。 分布式环境下Session的共享问题，分布式环境下，因为cookie储存在客户端浏览器中，每次访问不同的服务器都会携带会话状态信息，所以不存在不同服务器会话不一致问题，但是会有其他的问题，比如说，大小和数量限制问题导致的Cookie丢失，安全问题，cookie窃取，虽然可以设置HttpOnly属性防止私密Cookie被访问（加密Cookie,维护问题）。Session的共享需要放置在分布式缓存当中，MemCache集群，Tail等，分布式缓存框架的实现：重新实现HttpSession接口，定义自己的Session操作类，这个操作必须在进入应用之前完成，所以需要一个拦截器Filter拦截进入Mvc框架之前的请求，并封装HttpRequest和HttpResponse,然后根据SESSIONID获取到用户的私密信息（从分布式缓存中获取），然后将我们自己定义的Session对象设置到request和response对象中，最后将最新的会话信息保存到分布式缓存中。 BIO和NIO：BIO:同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成,NIO:同时支持阻塞与非阻塞模式，但这里我们以其同步非阻塞I/O模式来说明,selector(多路复用器)不断轮询IO的状态，只有在channel有Buffer可读或者可写时，应用程序才去处理它，在线程的使用上，就不需要一个IO请求对应一个处理线程了，而是在确实是需要进行IO操作是，才会使用一个线程去处理，这样避免了BIO模型下大量线程处于阻塞等待的情景。相对于BIO的流，NIO抽象出了channel作为输入输出的通道，并且提供了buffer的支持，在进行读操作时，需要使用buffer分配空间，然后将数据从channel中读入Buffer中，对于写操作，需要将数据写入Buffer中，然后将buffer写入Channel中 List和HashMap: HashMap1.7 :给定的默认容量是16，负载因子为0.75，map在使用过程当中当元素容量达到了阈值时即负载因子*默认容量时，开始进行扩容操作，扩容操作是一项非常耗费性能的操作，需要进行rehash,数据复制等操作，建议提前预估HashMap的大小，减少扩容带来的性能损耗，Entry[]即table, put方法解析： 判断当前数组是否需要初始化，如果Key为空，则puty一个空值进去， 根据Key计算出hashcode，根据计算出的hashcode定位出所在的桶，即数组的索引， 如果对应索引的元素（Entry）是一个链表，则需要遍历判断里面的hashcode,key是否和传入的key相等， 如果相等则进行覆盖，如果该索引处的元素为空，说明当前位置没有数据存入，直接新增一个Entry对象写入当前位置 jdk1.8:put方法(): 首先初始化table是否为空，如果为空则在resize()方法中进行初始化操作， 然后计算该key（根据hash值）在table中的索引位置，如果该索引处的桶为空，则没有发生冲突，直接在此位置上new一个新桶即可。 否则则比较当前桶的key和hash是否和传入的key和hash是否相等，相等就赋值给e,后续会进行覆盖操作， 上面条件若不成立则会进行判断是否是树节点，如果是红黑树，则按照红黑树的方式进行put. 上面两条件若都不成立，则进行判断是否为链表，若是，则遍历链表，查看是否有和传入的key相同的链表元素存在，查找到会结束循环.否则则在该桶后append链表元素。当链表的长度达到转变为红黑树的阈值时，将链表转化为红黑树，结束循环。 如果e不等于null,就相当于存在相同的key,那就需要将值覆盖，最后判断是否需要进行扩容. 注解@Autowired,@Inject,@Resource @Autowired是spring自带的，@Inject是JSR330规范实现的，@Resource是JSR250规范实现的，需要导入不同的包 @Autowired、@Inject用法基本一样，不同的是@Autowired有一个request属性 @Autowired、@Inject是默认按照类型匹配的，@Resource是按照名称匹配的 @Autowired如果需要按照名称匹配需要和@Qualifier一起使用，@Inject和@Name一起使用 线程启动方式：实现Runable,继承Thread,实现Callable接口（具有返回值，超时异常），start()会启用一个线程，执行这个线程类的run()方法里的代码块，run()会被当做普通方法。 ioc 容器的初始化:AbstractApplicationContext.refresh()方法，大体分为三个步骤 BeanDifinition的Resource定位 BeanDifinition的载入与解析(涉及bean的解析过程非常复杂，功能被分的很细，因为涉及到的扩展点很多，一个配置节点有很多东西，必须保证足够的灵活性，应对可能的变化)。 BeanDifinition在Ioc容器中的注册 类被加载的时机：（从被加载到虚拟机内存，到卸载出内存为止，实例化）加载，连接, 初始化，使用，卸载 衡量一个服务性能的高低好坏（Tps）:每秒事务处理数。影响tps的主要是并发处理能力。 java 内存模型：java内存模型的主要目标是定义程序中各个变量的访问规则 ，JVM中的变量和 代码中的变量定义不同，JVM的变量指的是实例变量，静态变量和构成数组的元素，但不包括方法内的局部变量和实参变量，因为方法内的变量是线程私有的，不存在共享问题。 主内存和工作内存的交互协议：Java内存模型定义了8种操作来实现变量的交互细节，这8中操作都是原子性的，不可分割的（double和long类型例外）分别是： lock:作用于主内存的变量，他把一个变量标识为线程独占的状态。 unlock:作用于主内存的变量，他把一个处于锁定状态的变量释放出来，此后这个变量才能被其他线程锁定。 read:作用于主内存的变量，他把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load:作用于工作内存的变量，他把read操作传输过来的值放入工作内存的变量副本中。 use:作用于工作内存的变量，他把工作内存中国一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值得字节码指令时将会使用此操作。 assign(赋值):作用于工作内存的变量，他把一个执行引擎接收到的值赋给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store(存储):作用于工作内存的变量，他把工作内存中一个变量的值传送到主内存中，以便以后的write使用。 write:作用于主内存中：他把store操作从工作内存中得到的变量的值放入主内存的变量中。 volitail变量的特殊规则，volitail类型变量能保证可见性和禁止指令重排序，但无法保证运算场景的并发安全性，因为对volitail类型的运算可能不是线程安全的，有两种情况他是线程不安全的： (1)运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 (2)变量不需要你与其他状态变量共同参与不变约束。 在ajax post 请求中，请求体数据可以是两种类型，既content-type:application/x-www-form-urlencoded或者是application/json, application/xml这种，前者常用来发送简单的请求体数据，如{“a”:”b”,”c”:1}，在SpringMVC的处理也比较简单，传入几个参数，控制器方法几个参数即可，默认这种简单数据类型转换是由ConversionService配置的转换器完成，同样，也可在方法的参数上注入@RequestParam 注解，效果相同，（此注解只针对String,int等基本数据类型的转换)。 另外，针对对象类型既model类的请求体，通常采用@ResponseBody 注解在相应的方法参数上，作为ajax 请求体数据的映射，@ResponseBody 也可以省略，@ResponseBody通常和ContentType:application/json, ContentType:application/xml,搭配使用。 最后，针对既有对象类型，又有普通数据类型的请求体数据，可在前端将请求体转化为Json字符串，在拼接成一个基本数据类型的请求体,如{“key”:”JSon字符串”}，后端MVC只通过简单的@RequestParam注解即可获取相应的值，然后进行JSON字符串的解析即可拿到相应的里面的对象和其他基本数据类型。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>Java Web - 面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nettyt通信框架实战]]></title>
    <url>%2F2018%2F09%2F17%2FNettty%E9%80%9A%E4%BF%A1%E6%A1%86%E6%9E%B6%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Netty_Server启动流程 Netty中的Reactor线程模型的主体类关系图 AbstractServerBootStrap分析 服务启动的方法入口是sbs.bind(port),需要验证sbs(ServerBootStrap)对象绑定的Group和channel和InetSocketDresss是否为空,不为空继续下一步，接下来就是初始化并且注册到Selector上去，绑定到本地端口。 initAndRegister() 123456789101112131415161718192021222324252627final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); init(channel); &#125; catch (Throwable t)&#123;&#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; &#125; &#125;``` channelFactory.newChannel()方法，其中channelFactory在AbstractBootStarp类中被赋值的地方可以发现: &gt; channel() ```Javapublic B channel(Class&lt;? extends C\&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException("channelClass"); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass)); &#125; 其实他是一个ReflectiveChannelFactory实例，进入此实例中发现其工厂类真正实现方法主体如下: newChannel() 12345try &#123; return clazz.newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException("Unable to create Channel from class " \+ clazz, t); &#125; channelClass其实就是我们在Server启动类中调用的serverBootStrap.group.channel(NioServerSocketChannel.class),由此可见，这里真正的Channel实例就是NioServerSocketChannel，在NioServerSocketChannel类的初始化过程中，初始化了一系列的netty核心组件，如Channel ,ChannelConfig,ChannelId,Unsafe,ChannelPipline,ChannelHandler等。 然后我们进入init方法，实现是在其子类ServerBootStrap中,此方法的前戏是对一些我们在启动类中的属性和选项的设置，略过，真正主体是如下方法代码, init() 12345678910111213141516171819202122232425//...channel.config().setOptions(options);//...channel.attr(key).set(e.getValue());//...ChannelPipeline p = channel.pipeline();//新连接 channel 的 ChildOptions 和 ChildAttr 设置...//新连接 channel 加入处理p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); init方法也并没有将此channel 注册到某个事件循环器上只是初始化了该serverChannel的一些属性，还有当有新的连接channel进来时的一些属性设置,并且将这些新的连接的属性封装成一个接入器对象里面，将这个接入器对象放入到该serverChannel的管道对象中，这些新的连接的处理都在Reactor事件循环器中被异步处理，继续进行下一个方法分析，ChannelFuture regFuture = config().group().register(channel);，通过ChannelConfig拿到EventLoopGroup对象，再进入到EventLoopGroup的实现MultithreadEventLoopGoup的register(channel)方法中。 MultithreadEventLoopGroup： 1234@Override public ChannelFuture register(Channel channel) &#123; return next().register(channel); &#125; next()方法是EventExecutorChooser定义的方法，EventExecutorChooser.next()方法的默认实现是DefaultEventChooserFactory,查看此工厂类可知时间执行选择器的实现有两种（根据EvenetExecutor数组的长度是否是2的整数次幂决定选用那种Chooser），每种chooser获取eventExecutor的方式不同，一种是idx和数组长度做与运算，一种是idx模除数组长度，取绝对值拿到数组下标，取得对应的EventExecutor对象。获取到对象的EventExecutor对象后，强转为EventLoop接口对象，跳转到SingleThreadEventLoop类的register方法中，如下所示： SingleThreadEventLoop 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Override public ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this)); &#125; @Override public ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.*checkNotNull*(promise, "promise"); promise.channel().unsafe().register(this, promise); return promise; &#125;``` 拿到前期已经初始化的*AbstractUnsafe*对象进行注册操作，进入register方法中,判断事件循环执行器是否已经绑定到该ServerChannel上,判断该事件循环执行器是否属于NioEventLoop，既是否兼容，然后将该事件循环器绑定到该serverChannel上 =&gt; *AbstractChannel.this.eventLoop = eventLoop* ,然后判断当前线程是不是事件循环执行器线程，如果是，执行register0()方法. &gt; AbstractChannel.AbstactUnsafe implements Unsafe```Java@Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; throw new NullPointerException("eventLoop"); &#125; if (isRegistered()) &#123; promise.setFailure(new IllegalStateException("registered to an event loop already")); return; &#125; if (!isCompatible(eventLoop)) &#123; promise.setFailure( new IllegalStateException("incompatible event loop type: " + eventLoop.getClass().getName())); return; &#125; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; logger.warn( "Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; &#125; register0方法中，先进行doRegister方法的调用，然后调用管道的invokeHandlerAddedIfNeeder(),方法，此时，handler才是被正式加入到pipline管道中。然后出发channel注册事件，该handler和pipeline管道正式进行绑定成功，在进行isActive()方法判断的时候，返回值为false,管道的fireChannelActive()方法未被执行. 1234567891011121314151617181920212223242526272829private void register0(ChannelPromise promise) &#123; try &#123; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125; 至此，register方法执行完毕，initAndRegister方法也执行完了，返回一个ChannelFuture对象到doBind()方法中：最后在此方法中进行一系列的判断，到达doBind0()方法： AbstarctBootStrap 1234567891011121314private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;); &#125; doBind0中的bind操作被加入到reactor线程组中异步执行绑定操作，我们定位到bind方法中，首先进入到AbstractChannel中的bind方法，接着进入到DefaultChannelPipline中的bind方法。 AbstractChannel 1234@Overridepublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return pipeline.bind(localAddress, promise);&#125; DefaultChannelPipline 1234@Overridepublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return tail.bind(localAddress, promise);&#125; tail 对象在创建默认管道对象的时候被创建，现在不用理会，继续往下跟进，进入到 AbstractChannel.AbstractUnsafe-&gt;NioMessageUnsafe 12345678910111213141516171819202122@Override public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; assertEventLoop(); //... boolean wasActive = isActive(); try &#123; doBind(localAddress); &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); closeIfClosed(); return; &#125; if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise); &#125; 此方法的wasActive 是false,进入到dobind(localAddress)方法中： NioServerSocketChannel 12345678@Override protected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.*javaVersion*() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125; &#125; 这里面的代码是调用JDK的Socket端口绑定方法进行绑定。绑定后 isActive()方法就是返回true了（已经被绑定成功），就会进入上个方法if判断条件中，进入下一步的pipline.fireChannelActive()方法。 DefaultChannelPipline 12345@Overridepublic final ChannelPipeline fireChannelActive() &#123; AbstractChannelHandlerContext.invokeChannelActive(head); return this;&#125; AbstractChannelHandlerContext 12345678910111213141516171819202122232425static void invokeChannelActive(final AbstractChannelHandlerContext next) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelActive(); &#125; else &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; next.invokeChannelActive(); &#125; &#125;); &#125;&#125;private void invokeChannelActive() &#123; if (invokeHandler()) &#123; try &#123; ((ChannelInboundHandler) handler()).channelActive(this); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125; &#125; else &#123; fireChannelActive(); &#125;&#125; 拿到ServerChannel的事件循环执行器，next对象即是abstractChannelHandlerContext对象。继续进入((ChannelInboundHandler) handler().channelActive(this)方法。此方法第一次调用时会进入如下； DefaultChannelPipline.HeadContext 12345@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive(); readIfIsAutoRead();&#125; 继续向下执行回调到AbstactChannelHandlerContext类中的方法,又会执行到((ChannelInboundHandler) handler().channelActive(this)方法，这里的handler()方法每次返回的对象都不一样，导致这个方法会重复调用三次，第二次调用channelActive(this)方法会进入到ChannelInboundHandlerAdapter中， ChannelInboundHandlerAdapter 1234@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive();&#125; 方法执行回到AbstractChannelHandlerContext中，会第三次调用ChannelActive(this)方法， AbstractChannelHandlerContext 12345@Override public ChannelHandlerContext fireChannelActive() &#123; final AbstractChannelHandlerContext next = findContextInbound(); *invokeChannelActive*(next); return this;&#125; 第三次调用channelActive(this)方法会跳转到，DefaultChannelPipline.TailContext的方法中： DefaultChannelPipline.TailContext 12@Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; &#125; 自此，执行完毕。]]></content>
      <tags>
        <tag>Netty</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eureka_源码解析]]></title>
    <url>%2F2018%2F08%2F27%2Feureka-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[微服务应用使用eureka作为注册中心的核心注解@EnableDiscoveryClient12345678@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;EnableDiscoveryClientImportSelector.class&#125;)public @interface EnableDiscoveryClient &#123; boolean autoRegister() default true;&#125; 主要类关系图 DiscoveryClient(com.netflix包下的Eureka client相关)此类是真正实现服务获取，服务注册，续约，的相关类，在此类的构造函数中1234567@Inject DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider&lt;BackupRegistry&gt; backupRegistryProvider) &#123; this.RECONCILE_HASH_CODES_MISMATCH = Monitors.newCounter("DiscoveryClient_ReconcileHashCodeMismatch"); this.FETCH_REGISTRY_TIMER = Monitors.newTimer("DiscoveryClient_FetchRegistry"); // ..... this.initScheduledTasks(); // ..... 有一个初始化定时任务函数，这个函数内部就是和服务注册相关的，进入此函数12345678910111213141516171819202122232425262728293031323334353637383940private void initScheduledTasks() &#123; int renewalIntervalInSecs; int expBackOffBound; if (this.clientConfig.shouldFetchRegistry()) &#123; renewalIntervalInSecs = this.clientConfig.getRegistryFetchIntervalSeconds(); expBackOffBound = this.clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); this.scheduler.schedule(new TimedSupervisorTask("cacheRefresh", this.scheduler, this.cacheRefreshExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.CacheRefreshThread()), (long)renewalIntervalInSecs, TimeUnit.SECONDS); &#125; if (this.clientConfig.shouldRegisterWithEureka()) &#123; renewalIntervalInSecs = this.instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); expBackOffBound = this.clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: renew interval is: " + renewalIntervalInSecs); this.scheduler.schedule(new TimedSupervisorTask("heartbeat", this.scheduler, this.heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new DiscoveryClient.HeartbeatThread(null)), (long)renewalIntervalInSecs, TimeUnit.SECONDS); this.instanceInfoReplicator = new InstanceInfoReplicator(this, this.instanceInfo, this.clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); this.statusChangeListener = new StatusChangeListener() &#123; public String getId() &#123; return "statusChangeListener"; &#125; public void notify(StatusChangeEvent statusChangeEvent) &#123; if (InstanceStatus.DOWN != statusChangeEvent.getStatus() &amp;&amp; InstanceStatus.DOWN != statusChangeEvent.getPreviousStatus()) &#123; DiscoveryClient.logger.info("Saw local status change event &#123;&#125;", statusChangeEvent); &#125; else &#123; DiscoveryClient.logger.warn("Saw local status change event &#123;&#125;", statusChangeEvent); &#125; DiscoveryClient.this.instanceInfoReplicator.onDemandUpdate(); &#125; &#125;; if (this.clientConfig.shouldOnDemandUpdateStatusChange()) &#123; this.applicationInfoManager.registerStatusChangeListener(this.statusChangeListener); &#125; this.instanceInfoReplicator.start(this.clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); &#125; else &#123; logger.info("Not registering with Eureka server per configuration"); &#125; &#125; 在 if (this.clientConfig.shouldRegisterWithEureka()) 分支内实现了服务续约和服务注册的功能，服务注册和服务续约是两个共生功能，服务续约使用心跳的方式去续约。具体实现注册则是在 this.instancewInfoReplicator.start(…)方法中，这个线程的run()方法如下 1234567891011121314151617181920212223242526272829303132333435public void run() &#123; boolean var6 = false; ScheduledFuture next; label53: &#123; try &#123; var6 = true; this.discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = this.instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) &#123; this.discoveryClient.register(); this.instanceInfo.unsetIsDirty(dirtyTimestamp); var6 = false; &#125; else &#123; var6 = false; &#125; break label53; &#125; catch (Throwable var7) &#123; logger.warn("There was a problem with the instance info replicator", var7); var6 = false; &#125; finally &#123; if (var6) &#123; ScheduledFuture next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); &#125; &#125; next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); return; &#125; next = this.scheduler.schedule(this, (long)this.replicationIntervalSeconds, TimeUnit.SECONDS); this.scheduledPeriodicRef.set(next); &#125; 不难看出，this.discoveryClient.register()是真正的注册方法，进入此方法1234567891011121314151617boolean register() throws Throwable &#123; logger.info("DiscoveryClient_" + this.appPathIdentifier + ": registering service..."); EurekaHttpResponse httpResponse; try &#123; httpResponse = this.eurekaTransport.registrationClient.register(this.instanceInfo); &#125; catch (Exception var3) &#123; logger.warn("&#123;&#125; - registration failed &#123;&#125;", new Object[]&#123;"DiscoveryClient_" + this.appPathIdentifier, var3.getMessage(), var3&#125;); throw var3; &#125; if (logger.isInfoEnabled()) &#123; logger.info("&#123;&#125; - registration status: &#123;&#125;", "DiscoveryClient_" + this.appPathIdentifier, httpResponse.getStatusCode()); &#125; return httpResponse.getStatusCode() == 204; &#125; 此方法中的this.eurekaTransport 内部类是DiscoveryClient实现的一个HTTP请求包装类，利用其中的一些属性进行Restful风格的请求注册，具体实现类应为RestTemplateEurekaHttpClient，此实现类实现了EurekaHttpClient,并将注册请求发送给服务端，客户端拿到响应进行响应的处理返回。说完服务注册，服务续约相关的主要是两个变量,如下两个变量主要控制服务续约相关，renewIntervalInsecs是调整服务续约任务的调用间隔时间，expBackOffBound是定义服务时效时间。对应配置文件的两个设置项。 12renewalIntervalInSecs = this.instanceInfo.getLeaseInfo().getRenewalIntervalInSecs();expBackOffBound = this.clientConfig.getHeartbeatExecutorExponentialBackOffBound(); 服务获取对应的逻辑判断条件是if (this.clientConfig.shouldFetchRegistry()) 这个属性对应的也是配置文件中的一个属性 eureka.client.fetch-registry=true 默认为true.为了定期更新客户端的服务清单，需要一个定时任务去从服务端获取服务清单，这个定时任务的频率可以设置，具体配置属性就是eureka.client.registry-fetch-interval-seconds= xxx 。服务获取的内部具体实现分为第一次获取和刷新缓存服务清单（非第一次获取）new DiscoveryClient.CacheRefreshThread()方法。对于服务续约，具体的实现函数为new DiscoveryClient.HeartbeatThread(null)，都是发送的Rest请求进行。 Eureka Server(服务端)Eureka Server 对于Rest请求的处理都在com.netflix.eureka.resources包下。在ApplicationResource类中， 12345678@POST@Consumes(&#123;"application/json", "application/xml"&#125;)public Response addInstance(InstanceInfo info, @HeaderParam("x-netflix-discovery-replication") String isReplication) &#123; logger.debug("Registering instance &#123;&#125; (replication=&#123;&#125;)", info.getId(), isReplication); // ....对传来的实例的元数据信息进行校验 registry.register(info ,"true".equals(isReplication)); return Response.status(204).build();//204 转发 &#125; register中的注册的具体实现为InstanceRegistry类的register重写方法，如下1234public void register(InstanceInfo info, boolean isReplication) &#123; this.handleRegistration(info, this.resolveInstanceLeaseDuration(info), isReplication); super.register(info, isReplication);&#125; 其中 handleRegistration方位是将新服务注册的事件传播出去，然后调用父类中的register方法，将InstanceInfo中的元数据信息存储在一个两层的ConcurrentMap中，第一层的key是 appName.,第二层的key是 instanceId,也就是说同一个服务名可以对应多个服务Id,id默认采用主机名实现不同，这使得无法在同一主机上启动多个相同微服务实例，spring cloud 对原生的Eureka InstanceInfo 实例做了优化，默认生成id会采用如下优先级规则： ${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}} 相关的客户端配置属性为: 下为配置实例id为应用成名+随机整数区分、 eureka.instance.instanceId=${spring.application.name:${randon.int}} 调用时按照一定的策略去调用。]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发相关]]></title>
    <url>%2F2018%2F07%2F14%2F%E5%B9%B6%E5%8F%91%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[并发模型并发系统可以采用多种并发编程模型实现，并发模型制定了系统中对作业的协调和分配，不同的操作系统有不同的分配方式，同时线程间的协作和交互方式也不同，故效率也有所不同. PPCPPC(Process Per Connection): 每次有新的连接就新建一个进程专门处理这个连接的请求。父进程通过预先fork 子进程，在子进程里处理连接的读写请求和业务操作。进程创建占用内存资源高，父子进程通信复杂，连接关闭需要所有父进程中的子进程都关闭才能正确的被关闭。 TPCTPC (Thread Per Connection): 每次有新的连接就新建一个线程专门处理这个连接的请求，共享进程内的内存空间，线程间的通信方式也更简单。高并发是还是存在性能问题，线程间的共享和互斥会导致死锁问题，某一进程中的线程异常会导致进程直接退出。 ReactorPPC模式最主要的问题就是每个连接都要创建一个进程，连接使用完毕就被销毁，进程也被销毁，没有考虑到复用，Reactor模式，也成为反应堆模式，采用了池化技术，建立进程池，将连接分配给进程池里的进程，一个进程可以accept多个来自客户端的连接。并且对连接的数据处理做了优化，采用IO多路复用技术，提高了IO的利用效率，意思是将进程连接中的数据处理转变为非阻塞的，只有当一个连接有数据需要处理时进程才会去处理，一个进程不会一直阻塞在某一个连接的业务处理数据上。 SynchornizeJava对象头和moniter Java对象头 Java对象头是指在虚拟机中存储对象相关的一些信息，其中就包括synchornize 持有的对象锁；Java对象头包括两个部分，Kclass Pointer (类型指针) 和MarkWord(标记字段)，类型指针指向内存中类元数据，MarkWord 用于存储对象运行时的数据。 MarkWord 存储的对象的运行时数据包括哈希码，GC分带年龄，锁状态标志，线程持有的锁，偏向线程id（偏向锁），偏向时间戳等 Kclass Pointer 虚拟机通过这个指针来确定某个对象是那个类的实例 MointerMoniter为一个同步工具，同时也是一个对象,Moniter是线程私有的数据结构，每一个线程都会有一个可用的 moniter record(监控记录表)，每一个被锁住的对象都和一个moniter相关连，moniter中的某个字段存储拥有该锁的该线程相关的东西，如该线程ID。 基于Synchornize的锁优化jdk1.6以后对Synchronize这种锁实现了大量的优化选项，如自旋锁，适应性自旋锁，锁消除，锁粗化，偏向锁 轻量级锁等技术来提高锁的性能，减少对性能的开销。 锁的状态（从低到高）:无锁态-&gt;偏向锁态-&gt;轻量级锁态-&gt;重量级锁态。（锁只能升级不能降级）。 自旋锁 线程的阻塞和唤醒状态的切换需要CPU从用户态（CPU较低特权-用户空间）转化为核心态（CPU较高特权-底层），同时，大多数应用线程对锁的持有都是短时间且频繁的，这种频繁的切换势必会导致CPU负载的提高和性能消耗（态的转化），自旋锁的出现就是为了解决这种问题，自旋锁就是让线程等待一段时间（执行一段时间无意义的代码），不会被立即挂起（进入阻塞状态），这是以占用CPU的执行时间片为代价的（CPU的并行时间片处理方式），但是如果有些线程持有的自旋锁迟迟不肯释放，就会白白浪费CPU的执行资源，所以，自旋不能完全代替阻塞，只能说在某些场景上，比较适用，我们需要定义一个合适的自旋等待时间（自旋次数决定），如果超出这个时间还没释放锁，就可以认为这个线程不适用适用自旋锁，应该改用立即挂起（线程阻塞方式）来持有锁。 锁消除 JVM基于对变量的逃逸数据分析（？），会消除无用的锁，既如果锁中的代码不存在共享变量和竞争，这种锁有时候不是显示的，有时候是隐式的，如Vector.add方法，StringBuffer.append()方法等等， 锁粗化 对于频繁的在一段代码内进行加锁，去锁的操作，会导致更多的cpu消耗，这时，使用锁粗化技术放大加锁的范围，减少加锁的次数可以明显提高性能。 轻量级锁 轻量级锁是由偏向锁转化而来的（可以认为他是比偏向锁的一个稍重的备份锁），轻量级锁的使用是在没有多线程竞争的情况下 ，减少重量级锁的性能消耗过大情况，每次获取锁，释放锁的操作依赖于底层多次CAS操作 重量级锁 重量级锁通过对象内部的Moniter对象实现的，本质上依赖于操作系统的Muter Lock指令实现 Volatile 定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。 volatile 可以保证变量对线程的可见性，被volatile 关键字修饰的变量，Java可以确保此变量对于所有线程来说，同一时刻，他们get到的都是相同的值，并且对该变量的更新，也会让所有的线程都知晓，表现为所有线程都能获取到此变量的最新的值。 volatile 无法保证复合操作的原子性，Java中基本数据类型的操作是原子性的. votalile 可以禁止指令重排序，volatile禁止重排序的实现是通过底层的内存屏障（lock前缀指令，一系列的指令）。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go基础实战]]></title>
    <url>%2F2018%2F05%2F02%2FGo%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Go语言基础Go（Golang） 作为一款Google 内部推行的开发语言，有很多其优点值得进行学习，下面是一遍基础的语法和实践，帮助认知和学习它. 一个Go 文件可以直接被运行，命令是：1go run main.go 但是Go 还是一门编译性语言，所以他的编译过程是存在的，编译命令为:1go build main.go Go的安装在Linux(CentOS)或者MacOS上都比较简单，在Windows上需要下载解压包，如：go1.11.2.windows-amd64.zip，官网下载，需要翻墙或者国内镜像，安装完成后，需要配置环境变量，*nix或者mac需要配置~/.bashrc文件，将export GOPATH=你的go的工作空间的位置缀入文件末尾即可。但是在win上，要配置GOROOT此项环境变量，如下图: .jpg) Go中的变量，变量声明方式有三种，分别是： 123var i int = 0var i = 0 i := 0 其中在循环判断中只能使用第三种变量声明方式，另外，全局变量建议使用第一种声明方式，局部变量使用第二种声明方式即可。 Go的循环语句只有for ,并且for的循环判断不需要括号，常规的循环中断也是支持的，包括 continue和break ，当然还有goto，当然goto 的建议用法是，不要用来控制流程中转，但是用到循环中断是可以的。其他的if else 判断也不需要括号，swtich 提供了两种方式的匹配，一种是值匹配，一种是表达式匹配： 1234567891011121314//第一种，值匹配switch x &#123;case 1: return 1default: return ""&#125;//第二种表达式匹配switch &#123;case param &lt; x : return ""default: return ""&#125; Go中的数据结构的数组有两种形式，一种是常规的静态数组，长度固定，类似Java。一种是切片，提供了灵活的长度变更的动态数组。数组变量的定义其实类似普通变量的定义，如：var arr [10]int, var arr [10]int = [10]int{1，…10},var arr = [10]int {1,…10 }, c:= [10]int{1,2,….10}]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud微服务实战-1]]></title>
    <url>%2F2018%2F05%2F02%2FSpringCloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[记录学习Spring-Cloud的中Eureka集群的问题在Eureka单节点的配置文件: application.properties: server.port=8081 eureka.instance.hostname=localhost eureka.client.register-with-eureka=false eureka.client.fetch-registry=false eureka.client.service-url.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/ 另外，在pom文件中需要加入Eureka相关的starter POMs,需要指定Spring-Cloud的版本号，此处使用Edgware.SR3（埃奇韦尔-伦敦一地铁站名字）版本号， &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR3&lt;/spring-cloud.version&gt; &lt;/properties&gt; ..... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; .... &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 之后在Spring-boot的主启动文件Application.java类的定义头上加入@EnableEurekaServer注解即可，启动应用程序，单机Eureka注册中心即建立完成，访问localhost:8081可查看Eureka注册中心的Web详情页。(2) Eureka server集群的建立原理是将自己作为服务向其他服务注册中心注册自己，这样就可以形成一组互相注册的服务注册中心集群，但是服务注册信息不会进行二次链式循环传播，即1注册到2,2注册到3,3注册到1，这种，服务在1注册的不会同步到3上，这在PeerAwareInstanceImpl类中体现。Server集群可在原有的单机项目基础上进行改建，只需增application-peer1.properties,application-peer2.properties,application-peer3.properties,三个相关的配置文件，并将原application.properties中的两个选项： eureka.client.register-with-eureka=false eureka.client.fetch-registry=false 两项false改成true,或者注解掉.因为默认是true,这两项配置的意思是是否允许Erueka server注册自己,是否检索服务。application-peer1.properties文件如下： spring.application.name=eureka-server server.port=8081 eureka.instance.hostname=peer1 eureka.client.serviceUrl.defaultZone=http://peer2:80822/eureka/，http://peer3:8083/eureka/ 其他两个文件与此文件类似，改写即可，然后在通过java -jar *.jar –spring.profiles.active=peer1，….. 命令分别启动三个服务注册中心应用，另:–需要提前在hosts文件中为每个分片配置地址解析 ： 127.0.0.1 peer1127.0.0.1 peer2127.0.0.1 peer3 在命令行中执行上述启动命令后，可能会报如下异常： 即连接超时Exception,这种状况是正常的，因为在你启动一个注册中心后，另外两个注册中心还没启动，此时尝试连接这两个，当然会连接超时。在所有注册中心都启动后，日志信息会正常输出。至此，Eureka Server高可用集群搭建完毕。]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试知识点整理-1]]></title>
    <url>%2F2018%2F04%2F28%2F%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86-1%2F</url>
    <content type="text"><![CDATA[JAVA基础部分：final,finally,finalize区别： final可以修饰方法，类，成员变量，当final修饰基本类型的成员变量时，该成员变量的值不可变，当fina修饰引用变量时，改引用指向的对象实体不可变，但是对象实体中的内容可变。当修饰类时，final和abstract不可同时使用，abstract意指该类是抽象的，用于扩展的。final修饰类时则意味着该类是不可被继承和扩展的。修饰方法时，该方法不可被重写。修饰形参时，该形参不可在方法内被重新赋值。 当方法内有定义内部类或者内部匿名类时，该方法的成员变量必须被final所修饰，因为在成员内部类中可能会修改该成员变量的值，这扩大了该变量的范围，造成安全隐患。 finally一般用在try catch 后，无论程序是否抛出异常，必定会执行finally中的语句块，一般用于IO资源的释放，或者连接资源的释放。 finalize是Object中的一个方法，用于资源回收。Exception,Error： 都继承自Throwable，error属于非受检类型，一般是底层资源错误或者系统错误 Ex:栈溢出,或者OOM(堆内存溢出)，不能在应用代码级别被处理. Exception分为 RuntimeException(运行时)和其他Exception（编译时）,RuntimeException也属于非受检类型，通常指应用程序运行中出现的bug导致的，Ex:NullPointerException,ArrayIndexOutOfBoundException,ClassCastException,IllegalStatementException其他Exception属于受检类型，编译时异常如 IO Exception。异常的处理方式：提倡提早捕获，延迟抛出。出现异常时，若可以解决则捕捉，不能解决则抛出。Integer和int（包装类和拆箱，装箱）: Integer是int的包装类，基本类型都有包装类，包装类能自动转化成相应的基本数据类型，称为拆箱，如包装类做算数运算时，反之（new Integer(1)），称为装箱。装箱和拆箱的设计是一种享元设计模式（它使用共享物件，用来尽可能减少内存使用量以及分享资讯给尽可能多的相似物件）,在装箱的时候，对于在-128到127的int值，Integer会从IntegerCache中拿到相应的复用对象。当大于127时，会重新new一个Integer对象。StringBuffer,StringBuilder,String: String的具体实现为 final char value[],他是immutable的（不可变对象），不会存在多线程访问的安全问题，但是性能会有所降低，所以提供了一个可变对象StringBuffer,由于考虑到多线程并发访问的问题，StringBuffer被设计成了Synchronized修饰的，1.5以后，为了提升StringBuffer在单线程下的性能，引入了StringBuilder，StringBuilder和StringBuffer的方法相同，当做字符串连接 ‘+’的使用被编译器所优化，直接在编译期生成一个String对象，如果该对象对象的字符串变量在常量池中已经存在，那么用+ 比用StringBuffer或者StringBuilder都要快，; 重载：在同一个类中，有多个方法名相同，形式参数列表不同的方法，与修饰符无关，与方法的返回值无关。 重写：子类重写父类方法，只有实例方法可以被重写，静态方法不可以被重写，重写的方法签名相同，但访问权限必须大于等于父类的方法，异常是夫类的子类，返回值必须小于父类的返回值，修饰符可以随意更改。 抽象类和接口：抽象类的目的是对根源的抽象，因为在Java中的单继承中只能继承一个抽象类，在这个抽象类中，你必须抽象或者实现所有可能子类要用的方法，但是接口是对动作的抽象，当你关注一个具体的操作时，使用接口。接口中的变量都是static类型的，而抽象类不是。 反射：反射的用途，用于在运行时获得一个类的具体内容或者调用一个类的方法，实现：JDK中的动态代理使用了反射(在运行时调用任意一个被代理类的方法，生成动态代理)Get和Post的区别： 表面上有以下几点不同，get是有缓存的，post没有，get可以刷新和回退，post需要重新提交表单，get对数据长度有限制(url最大2048)，而post时没有数据长度的限制。 安全性：post比get更安全，get请求里的所有数据都会显示在URL里，Post的参数不会被保存在浏览器上或者Web服务器日志上。 但从本质语义上的区别时：Get的语义请求是获取指定的资源，它是，安全，幂等，可缓存的，get方法的报文主体没有任何语义，Post是根据报文主体对指定的资源进行处理具体的处理方式视资源类型不同而不同。Session和cookie的区别： Http是一种无状态协议，无法保存每次客户端连接时的用户数据（会话保持功能），诞生了Cookie和Session这两种会话跟踪功能，cookied的实现方式是在浏览器向服务器发送Http请求建立会话时，浏览器生成一个会话ID，每次访问你这个服务端，就会把相应的这个cookie给携带上，这就实现了长久的会话保持的功能。而Session和cookie不同点在于Session是由服务端生成的（一般是借助cookieId，但也可以不用），保存在服务端。MVC设计思想： MVC(model view controller)模型视图控制器模式：一种设计模式，在软件系统的设计中，展示层也被称为视图层，是給用户展示和交互的页面，视图层只是数据的输出终点，并没有真正的业务处理。而在 模型层中是一个数据规范，模型和视图具体的数据格式无关，所以他可以被应用在多个视图当中，这减少了代码的重用性，控制器接受用户的请求并操纵模型和视图去完成用户的需求，他会决定去操纵那个模型构件去处理请求并返回到指定的视图。equals和==： 对于String类型的引用对象，equals比较的是对象在堆中存储的实际内容，而==则比较的是这个对象的句柄引用，对于基本数据类型的对象，==比较的是值,equals不能比较基本数据类型，而对于其他引用对象，==和hashcode（默认继承的是Object中的hashcode方法）则比较的是对象在内存中的句柄引用。 hashcode和equals的方法的区别和联系：hashCode和equals两个都是比较对象是否相等的，重写的Object的equals方法比hashCode更严谨和全面，所以效率就比较低，但是hashcode方法虽然效率高，但是hash算法无法保证每个不同对象生成的hash值不同，既冲突，这是其不可靠的一面。同时。hashcode规范是：一个没有改变的对象调用equals方法时如果相同，则其hashcode方法比较的也必须一致，反之，如果两个对象的hashcode方法得到的唯一散列值一致，则这个对象的equals比较的结果不一定相同。值传递和引用传递： Java中不存在真正的引用传递，所谓的引用传递和值传递都是指方法调用时参数的传值策略，而不是传递的内容（值或者引用）的类型，至于值类型和引用类型是区分内存分配的两种方式。函数的值传递会创建一个传入对象的副本，所以无法改变原有对象，在引用传递中，则不会创建副本，所以会改变传入的原始对象。在Java中，函数参数的传递方式是值传递，传递的值是引用。JAVA中常见集合部分：Collection: ArrayList:实现了基于动态数组的数组结构，默认长度为0，最大长度为Interger最大值-8，当数组长度超载时，每次增幅50%，因为内存中储存的地址连续，所以查询效率会比较高，删除和添加效率较低。 LinkedList:基于链表的数据结构，地址是任意的，所以在插入或者删除的时候，内存中对于地址的操作较为轻松。 HashSet：哈希表实现的，其中的数据是无序，不可重复的，根据hash函数区别重复元素可以放入null. LinkedHashSet：哈希表实现的有序，不可重复的集合。 TreeSet：二叉树实现的，有序的，不可重复的，不允许存储null值 Map:HashMap,ConcurrentHashMap 并发和多线程： 生产者和消费者模型： 可见性：当多线程的共享变量发生变化时，其他线程能看到变化后的值， 重排序：编译器或者cpu会在不改变单线程代码语义的前提下对代码的执行顺序进行优化，这可能会引发线程不安全。 原子性：对变量的操作具有不可分割性。 Synchronized和Lock:Synchronized是 Java内置的一个特性关键字，Lock是一个接口，Synchronized在发生异常时会主动释放锁，Lock需要主动调用unLock()方法来释放持有的锁，但是Lock可以让阻塞等待的线程响应中断，而Synchronized会一直阻塞下去（死锁），如果线程之间并发争抢资源不严重，Synchronized的性能比Lock要好，反之，则Lock的性能比较好。公平锁：等待时间长的线程优先获得锁。 wait和sleep的区别：每个对象都持有一个内部moniter对象，JVM会为每个对象维护两个“队列”，分别是EntrySet和WaitSet.EntrySet用于存储等待获取对象的内部moniter的所有线程，而waitSet用于存储执行了obj.wait/wait(long ms)方法的所有线程。sleep()方法属于Thread类，wait()方法属于Object类，sleep会导致当前线程让出cpu的使用权到指定的时间，期间仍然会保持对锁的监控状态，所以，调用sleep方法并不会释放线程所持有的锁，而wait方法会放弃该线程持有的锁对象，进入waitSet，此时线程状态为BLOCKED状态。当使用notify唤醒该线程时，线程状态标记为RUNABLE状态,线程进入EntrySet中和其他活跃线程争抢锁的持有权。 单机事务：事务的核心是锁和并发，四大特性是指原子性（Atomic）、一致性（Consistency）,隔离性（isolation）和持久性（duration）.2PL:数据库中的update,insert,delete都是先读后写的方式。处理事务常见的方式有排队法：单线程序列化读写，不需要冲突控制，但是对于硬盘一类的慢速设备性能较差，对于redis一类的内存数据库，内存和单个cpu绑定，针对此内存块的数据的读写操作都是在单个cpu上完成，既没有线程上下文切换的时候速度是最快的。对于慢速设备需要使用多线程和异步的方式对请求进行批量缓存提交，线程和请求之间没有绑定关系。排他锁：对事物之间的共享数据进行锁，完成数据库系统的访问控制。事务之间的调优原则是：尽可能减少锁的覆盖范围，表锁变行锁，增加锁上可并行的线程数量如：读锁和写锁，读写线程分离。并行读取数据，选择正确的锁类型：悲观锁适用于并发争抢比较严重的场景，乐观锁适合不怎么严重的场景。 分布式事务：分布式事务指的多个微服务之间的事务不一致导致的数据一致性问题。解决的办法最常用的是oracle 的xa二阶段提交协议，第一阶段，有一个协调中心节点向所有参与事务节点进行询问请求，所有参与节点进行各自事务相关的数据更新，并将更新日志写入undo log或者redo log中，用于提交或者回滚。当所有的参与节点返回成功给中心调节节点的时候，开始执行第二阶段，第二阶段，协调中心向所有参与者发送让他们commit的请求，所有参与者进行本地事务的提交，提交成功后，返回完成消息给中中心节点，，分布式事务完成。 并行是指两个或者多个事件在同一刻发生；并发是指两个或者多个事件在同一时间间隔发生； 进程是资源调度（指内存资源或者IO设备这种资源）的基本单位，线程是cpu调度的基本单位。 volatile是轻量级的synchronized,他在并发环境中保证了共享变量的可见性，并禁止重排序，原子性保证：但对long类型或者double类型的不行，因为那是两步操作 内存可见性：Java线程之间的通信由Java内存模型控制。JMM决定了一个线程对共享变量的操作结果何时对另一个线程可见，每个线程独有的本地内存，本地内存中存储了共享变量的副本，本地内存是JMM抽象出来的一个概念，实际并不存在。JMM通过插入特定的内存屏障指令来禁止cpu级别的指令重排序。JSP-133规范采用happens-before的概念来阐述操作可见性，在JMM中，如果一个操作的执行结果对另一个操作可见，那么这两个操作必定要存在happens-before关系，这样的操作可以不同的线程之间或者同一个线程之内。 CAS(compare and swap)Atomicxxx类型的变量和Lock操作类的底层都是实现了此机制，对变量的操作涉及到3个操作数，内存中的值，变量旧的预期值，要修改的值。当要修改时会检查内存中的值和变量旧的预期值是否相同，如果不同，则认为提交更新失败，线程会自旋等待一段时间后重新计算当前内存值，和要修改的新值。CAS对cpu的要求比较高，且只能保证一个变量的原子性，且存在ABA问题。ABA问题：A线程修改了变量的值为另一个，B线程比较当前旧预期值和内存中的值是相同的，然后阻塞，线程C将变量的值从另一个变更为原来的值，然后B拿到锁，开始执行CAS步骤，又将变量的值重新更新为另一个。解决方法，对变量添加版本号的标识，每一次的更新都会对版本号做变化，更新前会对版本号做对比，不同则不能更新。 线程安全的定义（周志明）：当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替进行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么称这个类是线程安全的 框架部分： RPC:调用本地函数一样调用远程其他虚拟机内的函数，屏蔽了底层的传输方式和序列化方式，降低了服务之间沟通的成本，gRPC：google开源的一款语言中立的RPC框架，基于Http2协议（双向流，消息头压缩,单TCP的多路复用，服务端推送）,基于IDL文件定义服务。通过proto3工具生成指定语言的数据结构、服务端接口和指定语言的客户端Stub,序列化支持PB(protocal Buffer)和json,PB是一种语言无关的高性能序列化框架。 tomcat:tomcat作为一个jsp/servlet容器，有三种工作模式：独立的servlet容器，进程内的servlet容器，进程外的servlet容器。tomcat在不同工作模式下的请求分为两类。tomcat作为应用程序服务器，请求来自于前端的Web服务器.tomcat作为独立服务器，请求来自于web浏览器。 No Sql相关： Redis的5中常用数据类型string（最大大小为512M）,list（双向链表），set(value永远为null的HashMap)，zset,hash(value是一个HashMap,适合存储对象). 支持pop/push,add/remove 操作，取交集和并集等原子性操作。支持序列化到磁盘或者文件。默认端口为6379. Redis的持久化策略：RDB:在指定的时间内将snapshot快照写入磁盘，恢复时将文件直接读入内存，场景分析：大规模数据的恢复，且对数据恢复的完整性不敏感。最后一次持久化后的数据可能丢失。 AOF:以日志的形式来记录每个写操作.使用场景：备份机制更稳健，丢失数据概率更低，日志文本可读。 Redis的消息订阅和发布：按照频道订阅，可以一次订阅多个，发布者发布后，收到消息。可以按照规则订阅，订阅多个，使用通配符* Redis的使用场景： 高速数据缓存服务， 分布式session共享：使用redis集群做session共享服务器， 分布式锁：最简单的方式在实例里创建一个键值，使用Jedis set（key,requestId,NX,EX,30000）;使用唯一key作为锁，相应的value作为对应的请求的Id,可避免加锁和解锁不是同一个人这种情况，使用过期时间可保证客户端宕机不会发生死锁的情况，锁到时间会自动删除，且必须保证任意时刻，只有一个客户端持有锁。 Redis集群采用一主多仆方式，或多主多仆方式，主（写）从（读）之间通过同步命令不断复制数据，仆服务器读取主的RDB文件。当主机挂掉，需要手动让仆成为主机，如果通过哨兵模式，仆服务器可自动成为主服务器 哨兵服务器:负责服务器的投票抉择问题，根据从服务器的优先级决定谁成为主服务器。 缓存问题： 缓存并发:缓存过期或者在更新，且同时存在大量并发请求该key，导致的缓存失效，请求直接到达数据库层会导致数据一致性问题，或者服务“雪崩”。解决方法是对查询缓存操作加锁，阻塞直至重建缓存。 缓存雪崩：当缓存失效时间相同时，可能导致同时大量缓存同时失效，导致数据库查询压力骤增，引发雪崩，可将缓存失效时间均匀平摊在时间轴上。 缓存击穿：某个key对应的数据为空，缓存没有命中，导致不必要的数据库查询操作，通过设置布隆过滤器，将有可能存在的数据hash到一个足够大的bitmap中。一个一定不存在的数据一定会被过滤掉，从而避免了请求直达数据库。 RDBMS数据库相关(mtsql)： 普通索引 唯一性索引,必须指定为primary key 全文索引单列索引，多列索引 聚集索引和非聚集索引：MyIsam的B+Tree的叶子节点上的data,并不是数据本身，而是数据存放的地址，其是非聚集索引.Innodb的数据文件本身就是索引文件，B+Tree的叶子节点上的data就是数据本身，key为主键，这是聚集索引，聚簇索引的数据的物理存放顺序与索引顺序是一致的。 B+树是为磁盘或其他直接存储辅助设备而设计的一种平衡查找树，所有记录节点都是按照键值得大小顺序存放在同一层的叶节点中，各叶节点以指针的方式进行连接。 MyIsam是mysql5.5.5以前的默认存储引擎，每个表在MyIsam中都以三个以表名命名的物理文件构成，分别是：.frm(表结构文件) .myd(表数据文件) .myi（索引文件），但是MyIsam不支持事务，查询效率较快，会存储表的行数，故count(*)函数很快。 Innodb也有.frm表结构文件，但是数据文件和索引文件是存储在一起的，有支持事务和安全的日志文件（很重要）回滚和恢复数据的重要手段。行级锁（高并发适用）、增删改性能较高因为不会重建表。count查询比MyIsam低（会遍历全表）。 索引可以加快查询效率，降低数据库的排序成本，因为索引就是对字段数据进行排序后存储的。如果待查询的字段和索引键字段一致，就可以不用排序了。但是索引会增加增删改操作带来的IO量和调整索引的计算量，还有空间的存储量也会占用，在对较频繁的字段的查询的时候可以使用索引，唯一性太差的字段也不适合索引，即使频繁被查询。增删改的操作大于检索操作的也不适用索引。MQ相关：(RocketMQ) mq异步解耦指的是：挡住前端请求数据的洪峰，保证后端系统的稳定性。异步要求服务端对数据的实时性要求不高，对数据的可靠性要求高。 使用场景：（1）发布订阅模式，（2）消息优先级有要求（3）消息有序性要求，如购物行为。（4）消息过滤，无用消息的处理（5）消息的持久化（数库库或者KV存储系统或者文件等））（5）回溯消费，消息重试，定时消息，分布式事务等等。JVM: 类的加载机制：类的加载值得时将类的.class文件中的二进制数据读入到内存中，将其放在运行时的数据区的方法内，然后再堆区创建一个java.lang.class对象，用来封装类在方法区内的数据结构，并提供了访问方法区内的这些数据结构的方法。 类的生命周期：加载（加载二进制数据到内存中），连接，初始化（静态变量赋初值，常量赋值），使用（new()） 和卸载 (垃圾回收)。 jvm初始化步骤：（1）假如这个类没有没加载和连接，则程序先加载并连接。(2)假如该类的直接父类没有被初始化，则先初始化其直接父类，假如类中有初始化语句，则系统依此执行这些初始化语句。 类初始化时机：只有当类的主动使用时才会导致类的初始化，主动使用的方式有： Sun JDK关于JVM监控和处理故障的命令: jps:JVM Process Status Tool:显示指定系统内所有的HotSpot进程(jps -l -m)jstat：JVM static Monitoring是用于监视虚拟机运行时状态信息的命令jmap:JVM Memory Map 用于生成heap dump文件，堆快照文件，一般用MAT工具进行分析，大对象无法被回收或者过多应该被回收的对象一直被引用。jstack:用于生成jvm当前时刻的线程快照，线程快照是当前JVM中每条线程的方法的执行堆栈集合，可以查询线程死锁或者循环等待等问题。jinfo:JVM Configure Info 用于查看和调整虚拟机的运行时参数，能看到更详细的，未被指定的参数。 linux 相关： cat[选项][文件]：查看文件内容，但是对于较大的文件不适合，会过多占用系统资源，无法进行交互和控制more[选项][文件]：分页查看文件、less[选项][文件]：更高级的查看和搜索文件内容的方式tail[-f（必要参数）][可选参数][文件]：查看文件的最后几行，一般用于日志文件的实时查看。head:查看文件的头几行。wc [选项参数][文件]：统计文件中字符的个数 数据结构和算法部分：]]></content>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql安装问题]]></title>
    <url>%2F2018%2F04%2F28%2FMySql-For-Windows7-Regedit-service-error%2F</url>
    <content type="text"><![CDATA[记一次Mysql注册服务相关问题mysql解压版本的正确启动： 需要配置环境变量，环境变量的配置建议在系统Path中配置，配置完bin目录后. 需要配置默认的my-default.ini配置文件，主要就是设置字符编码和basedir和datadir两个配置选项，分别为mysql的解压目录和mysql的数据存储目录，数据存储目录需要我们手动在mysql的根目录下建立data文件夹 初始化mysql命令:mysqld –initialize-insecure –user=mysql 注册mysql服务：mysqld –install mysql服务名（可自定义）–defaults-file=”mysql配置文件的路径”，注意，此处注册的mysql的配置文件不可以用其默认的my-default.ini，必须另外建立一个该文件的副本如my.ini,否则会导致服务启动失败，如下图所示：]]></content>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ实战(1)]]></title>
    <url>%2F2018%2F02%2F21%2FRocketMQ%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;RocketMQ是一款阿里自主开源的分布式消息中间件，其没有完全遵循JMS(JAVA Message Services)规范，并且和常用的ActiveMQ相比，具有很多优良的特性，并且在如今高负载，大流量的业务场景下完全可以胜任。 RocketMQ原生支持分布式，不用像ActiveMQ一样做额外的配置，单点式消息中间件 RocketMQ保证了消息的严格顺序，ActiveMQ可能会有消息错乱。 丰富的消息拉取模式。 亿级消息堆积能力 &nbsp;&nbsp;&nbsp;RocketMQ的发布订阅模式规定了其采用了Group机制实现消息的负载均衡。即根据Topic的消息数，均衡分布到每个Group相应的数据量，其中Group可以是一台机器或者一个进程。 RocketMQ的集群部署 多Master模式多个Master存在的模式，当一个Master宕机的时候，会由于其他的代替，缺点是宕机的Master上的消息无法再被订阅，除非复活。 多Master多Slave模式（同步双写）适用于并发量比较大的情况下，只有Master/Slave都成功才能成功，相比于异步辅助，提高了强一致性，但是减缓了读写速度 多Master单Slave模式（异步复制）Master/Slave有短暂的延迟，高可用模式，Master宕机的时候，Slavek可以读到消息，但是可能会有少量的信息丢失。]]></content>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaSE中的默认VM-HotSpot]]></title>
    <url>%2F2018%2F02%2F03%2FJavaSE%E4%B8%AD%E7%9A%84%E9%BB%98%E8%AE%A4VM-Hotspot%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;”hot spot”故名思意,就是热点的意思，在JVM的执行引擎中，热点又通常指执行频率高的代码，而执行频率高的评判标准则是有很多种表现，如方法的执行次数，或者某条执行路径的次数。HotSpot内部的执行引擎采用混合执行模式，即包括解释器和自适应编译器（Adaptive-compile）. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虚拟机的默认配置下，初始化时所有的Java方法都由解释器执行，解释器记录着每个方法的执行次数和循环次数，并以这两个指标去判断一个方法的”热度”。等到一个方法足够”热”的时候，JVM就会启动该方法的编译，这种在所有执行过的代码里只寻找一部分编译的做法，叫自适应编译，为了实现动态编译，执行引擎需要多层，且一定有一层是进程初始阶段的编译，然后再让自适应编译处理其中的部分代码。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JIT编译（Just-in-time）即每当一部分代码要第一次准备执行时，将这部分代码编译。同时JIT编译和自适应编译都属于动态编译的范畴，其特点是在程序运行的时候进行编译，而不是在程序开始之前就进行编译，和静态编译相互区分。而在HotSpot中的VM是使用”JIT编译的（动态编译）”。其中的Client Compile(C1)和Sever Compile(C2)通常被称为”JIT编译器”。]]></content>
      <tags>
        <tag>JVM</tag>
        <tag>JIT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作点滴0001]]></title>
    <url>%2F2017%2F08%2F16%2F%E5%B7%A5%E4%BD%9C%E7%82%B9%E6%BB%B40001%2F</url>
    <content type="text"><![CDATA[项目构建公司还在用svn,项目从里面checkout出来，然后ide导入本来是一件简单不过的事情，但是，但是，最后还是搞了一天，从侧面反映了自己这个农民工还是不熟练，详情如下。项目采用在IDE（eclipse）maven 导入的方式构建，经过漫长的jar包下载和配置文件Validation（后来才想起来该关掉这个……~.~），项目出现了3万+个errors,项目工程模块分的巨多，这也导致了问题排查的困难，一开始我也怀疑是maven配置文件的原因，最后真是，拿到了正确的配置文件，开心去替换了下，错误减少了点，而且剩下的大部分xxx cannot be resolved to a type这种错误，百度和google都试了一下，不得而解，最后试了某一个博客的方法，具体做法是： project-automatically 对勾给取消掉了，应该是防止自动构建用的选项， project-clean 项目clean 完毕,在progress视图里又看到了项目在自动构建（不解），可能会导致eclipse报错，栈溢出了（惊吓）。 项目右键，maven-update project,项目更新完毕，错误消失。 ###原因思考：网上的解释是eclipse和maven的clean并不同步（存疑解释）,另一种是因为某些特殊原因，eclipse没能自动编译(应该是maven生成的)源代码到build/classes（或其他classes目录），导致类型查找不到,(什么原因呢？) ###tips(项目执行这个命令会生成 mvn eclipse:eclipse 会自动生成相关的类文件，不需要在用maven 方式导入项目,以普通方式导入即可)。]]></content>
      <tags>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS[域名系统]基本解析]]></title>
    <url>%2F2017%2F06%2F27%2FDNS-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E6%9C%AC%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[DNS(Domain Name System)此协议根据域名解析到此域名对应的相应的ip地址，然后再来访问此IP地址对应得网站或者主机。首先，本机一定要知道DNS服务器的IP地址，否则上不了网，通过DNS服务器，才能知道某个域名的IP地址到底是什么,DNS服务器的IP地址，有可能是动态的，每次上网是由网关分配，这叫做DHCP机制，也有可能是事先固定的地址，一些公网的DNS服务器，也可以使用，其中最有名的就是Google的8.8.8.8和Level3 的4.2.2.2 过程采用了分级查询–域名的层级结构如下：主机名（这是用户在自己的域里面为服务器分配的名称，用户可以任意分配）.次级域名.顶级域名.root(根域名，默认是省略的)。每一级都有自己的NS记录（NameServer）此记录指向该级域名的域名服务器，此服务器知道下一级域名的各种记录。 DNS服务器内置了根域名服务器的NS记录和IP地址（这些记录一般是不会变化的，）根域名服务器全世界只有13台，分别是从A.root-servers.net到M.root-servers.net。 然后DNS服务器向所有这些根域名服务器的IP地址发出”0查询0“请求，询问索要查询的域名（如：www.douyu.com）的顶级域名服务器com.的NS记录，最先回复的根域名服务器将被缓存，以后只向这台服务器发送请求. 接下来，DNS服务器向这些顶级域名服务器发出请求，询问次级域名douyu.com的NS记录，返回了此次级域名的四条NS记录和其对应的服务器名称和IP。 最后，DNS服务器向这些次级域名发送查询请求查询。主机层www对应的NS记录，返回相应的主机服务器和其对应的IP.此IP即是我们要的结果IP。]]></content>
      <tags>
        <tag>tcp</tag>
        <tag>ip</tag>
      </tags>
  </entry>
</search>
